


@report{nhts_2009,
  title = {2009 {{National Household Travel Survey}}},
  url = {https://nhts.ornl.gov/documentation.shtml},
  author = {{U.S. Department of Transportation, Federal Highway Administration}},
  date = {2009}
}

@report{ramsey_smart_2014,
  title = {Smart {{Location Database}}: {{Version}} 2.0 {{User Guide}}},
  url = {https://www.epa.gov/smartgrowth/smart-location-mapping#SLD},
  institution = {{US Environment Protection Agency}},
  author = {Ramsey, Kevin and Bell, Alexander},
  date = {2014}
}

@article{albertBayesianAnalysisBinary1993,
	title = {Bayesian {Analysis} of {Binary} and {Polychotomous} {Response} {Data}},
	volume = {88},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476321},
	doi = {10.1080/01621459.1993.10476321},
	abstract = {A vast literature in statistics, biometrics, and econometrics is concerned with the analysis of binary and polychotomous response data. The classical approach fits a categorical response regression model using maximum likelihood, and inferences about the model are based on the associated asymptotic theory. The accuracy of classical confidence statements is questionable for small sample sizes. In this article, exact Bayesian methods for modeling categorical response data are developed using the idea of data augmentation. The general approach can be summarized as follows. The probit regression model for binary outcomes is seen to have an underlying normal regression structure on latent continuous data. Values of the latent data can be simulated from suitable truncated normal distributions. If the latent data are known, then the posterior distribution of the parameters can be computed using standard results for normal linear models. Draws from this posterior are used to sample new latent data, and the process is iterated with Gibbs sampling. This data augmentation approach provides a general framework for analyzing binary regression models. It leads to the same simplification achieved earlier for censored regression models. Under the proposed framework, the class of probit regression models can be enlarged by using mixtures of normal distributions to model the latent data. In this normal mixture class, one can investigate the sensitivity of the parameter estimates to the choice of {\textquotedblleft}link function,{\textquotedblright} which relates the linear regression estimate to the fitted probabilities. In addition, this approach allows one to easily fit Bayesian hierarchical models. One specific model considered here reflects the belief that the vector of regression coefficients lies on a smaller dimension linear subspace. The methods can also be generalized to multinomial response models with J {\textgreater} 2 categories. In the ordered multinomial model, the J categories are ordered and a model is written linking the cumulative response probabilities with the linear regression structure. In the unordered multinomial model, the latent variables have a multivariate normal distribution with unknown variance-covariance matrix. For both multinomial models, the data augmentation method combined with Gibbs sampling is outlined. This approach is especially attractive for the multivariate probit model, where calculating the likelihood can be difficult.},
	language = {en},
	number = {422},
	urldate = {2020-10-12},
	journal = {Journal of the American Statistical Association},
	author = {Albert, James H. and Chib, Siddhartha},
	month = jun,
	year = {1993},
	pages = {669--679}
}

@book{hoffFirstCourseBayesian2009,
	address = {New York},
	series = {Springer {Texts} in {Statistics}},
	title = {A {First} {Course} in {Bayesian} {Statistical} {Methods}},
	isbn = {978-0-387-92299-7},
	url = {https://www.springer.com/us/book/9780387922997},
	abstract = {This book provides a compact self-contained introduction to the theory and application of Bayesian statistical methods. The book is accessible to readers having a basic familiarity with probability, yet allows more advanced readers to quickly grasp the principles underlying Bayesian theory and methods. The examples and computer code allow the reader to understand and implement basic Bayesian data analyses using standard statistical models and to extend the standard models to specialized data analysis situations. The book begins with fundamental notions such as probability, exchangeability and Bayes' rule, and ends with modern topics such as variable selection in regression, generalized linear mixed effects models, and semiparametric copula estimation. Numerous examples from the social, biological and physical sciences show how to implement these methodologies in practice. Monte Carlo summaries of posterior distributions play an important role in Bayesian data analysis. The open-source R statistical computing environment provides sufficient functionality to make Monte Carlo estimation very easy for a large number of statistical models and example R-code is provided throughout the text. Much of the example code can be run ``as is'' in R, and essentially all of it can be run after downloading the relevant datasets from the companion website for this book. Peter Hoff is an Associate Professor of Statistics and Biostatistics at the University of Washington. He has developed a variety of Bayesian methods for multivariate data, including covariance and copula estimation, cluster analysis, mixture modeling and social network analysis. He is on the editorial board of the Annals of Applied Statistics.},
	language = {en},
	urldate = {2020-10-12},
	publisher = {Springer-Verlag},
	author = {Hoff, Peter D.},
	year = {2009},
	doi = {10.1007/978-0-387-92407-6}
}

@book{gelmanBayesianDataAnalysis2020,
	title = {Bayesian {Data} {Analysis}, {Third} {Edition}},
	isbn = {978-1-4398-4095-5},
	url = {http://www.stat.columbia.edu/~gelman/book/},
	abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors{\textemdash}all leaders in the statistics community{\textemdash}introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book{\textquoteright}s web page.},
	language = {en},
	publisher = {CRC Press},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	month = feb,
	year = {2020},
	keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General, Psychology / Research \& Methodology}
}

@book{robertBayesianChoiceDecisionTheoretic2007,
	title = {The {Bayesian} {Choice}: {From} {Decision}-{Theoretic} {Foundations} to {Computational} {Implementation}},
	isbn = {978-0-387-71598-8},
	shorttitle = {The {Bayesian} {Choice}},
	abstract = {This is an introduction to Bayesian statistics and decision theory, including advanced topics such as Monte Carlo methods. This new edition contains several revised chapters and a new chapter on model choice.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Robert, Christian},
	month = aug,
	year = {2007},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}


@article{polsonBayesianInferenceLogistic2013,
	title = {Bayesian {Inference} for {Logistic} {Models} {Using} {P{\'o}lya}{\textendash}{Gamma} {Latent} {Variables}},
	volume = {108},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2013.829001},
	doi = {10.1080/01621459.2013.829001},
	language = {en},
	number = {504},
	urldate = {2020-06-27},
	journal = {Journal of the American Statistical Association},
	author = {Polson, Nicholas G. and Scott, James G. and Windle, Jesse},
	month = dec,
	year = {2013},
	pages = {1339--1349}
}

@article{imaiBayesianAnalysisMultinomial2005,
	title = {A {Bayesian} analysis of the multinomial probit model using marginal data augmentation},
	volume = {124},
	issn = {0304-4076},
	url = {http://www.sciencedirect.com/science/article/pii/S0304407604000351},
	doi = {10.1016/j.jeconom.2004.02.002},
	abstract = {We introduce a set of new Markov chain Monte Carlo algorithms for Bayesian analysis of the multinomial probit model. Our Bayesian representation of the model places a new, and possibly improper, prior distribution directly on the identifiable parameters and thus is relatively easy to interpret and use. Our algorithms, which are based on the method of marginal data augmentation, involve only draws from standard distributions and dominate other available Bayesian methods in that they are as quick to converge as the fastest methods but with a more attractive prior specification. C-code along with an R interface for our algorithms is publicly available.11R is a freely available statistical computing environment that runs on any platform. The R software that implements the algorithms introduced in this article is available from the first author's website at http://www.princeton.edu/{\textasciitilde}kimai/.},
	language = {en},
	number = {2},
	urldate = {2020-11-14},
	journal = {Journal of Econometrics},
	author = {Imai, Kosuke and van Dyk, David A.},
	month = feb,
	year = {2005},
	keywords = {Bayesian analysis, Data augmentation, Prior distributions, Probit models, Rate of convergence},
	pages = {311--334}
}

@article{liuParameterExpansionData1999,
	title = {Parameter {Expansion} for {Data} {Augmentation}},
	volume = {94},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2669940},
	doi = {10.2307/2669940},
	abstract = {Viewing the observed data of a statistical model as incomplete and augmenting its missing parts are useful for clarifying concepts and central to the invention of two well-known statistical algorithms: expectation-maximization (EM) and data augmentation. Recently, Liu, Rubin, and Wu demonstrated that expanding the parameter space along with augmenting the missing data is useful for accelerating iterative computation in an EM algorithm. The main purpose of this article is to rigorously define a parameter expanded data augmentation (PX-DA) algorithm and to study its theoretical properties. The PX-DA is a special way of using auxiliary variables to accelerate Gibbs sampling algorithms and is closely related to reparameterization techniques. We obtain theoretical results concerning the convergence rate of the PX-DA algorithm and the choice of prior for the expansion parameter. To understand the role of the expansion parameter, we establish a new theory for iterative conditional sampling under the transformation group formulation, which generalizes the standard Gibbs sampler. Using the new theory, we show that the PX-DA algorithm with a Haar measure prior (often improper) for the expansion parameter is always proper and is optimal among a class of such algorithms including reparameterization.},
	number = {448},
	urldate = {2020-11-14},
	journal = {Journal of the American Statistical Association},
	author = {Liu, Jun S. and Wu, Ying Nian},
	year = {1999},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1264--1274}
}

@article{tannerCalculationPosteriorDistributions1987,
	title = {The {Calculation} of {Posterior} {Distributions} by {Data} {Augmentation}},
	volume = {82},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2289457},
	doi = {10.2307/2289457},
	abstract = {The idea of data augmentation arises naturally in missing value problems, as exemplified by the standard ways of filling in missing cells in balanced two-way tables. Thus data augmentation refers to a scheme of augmenting the observed data so as to make it more easy to analyze. This device is used to great advantage by the EM algorithm (Dempster, Laird, and Rubin 1977) in solving maximum likelihood problems. In situations when the likelihood cannot be approximated closely by the normal likelihood, maximum likelihood estimates and the associated standard errors cannot be relied upon to make valid inferential statements. From the Bayesian point of view, one must now calculate the posterior distribution of parameters of interest. If data augmentation can be used in the calculation of the maximum likelihood estimate, then in the same cases one ought to be able to use it in the computation of the posterior distribution. It is the purpose of this article to explain how this can be done. The basic idea is quite simple. The observed data y is augmented by the quantity z, which is referred to as the latent data. It is assumed that if y and z are both known, then the problem is straightforward to analyze, that is, the augmented data posterior p($\theta$ | y, z) can be calculated. But the posterior density that we want is p($\theta$ | y), which may be difficult to calculate directly. If, however, one can generate multiple values of z from the predictive distribution p(z | y) (i.e., multiple imputations of z), then p($\theta$ | y) can be approximately obtained as the average of p($\theta$ | y, z) over the imputed z's. However, p(z | y) depends, in turn, on p($\theta$ | y). Hence if p($\theta$ | y) was known, it could be used to calculate p(z | y). This mutual dependency between p($\theta$ | y) and p(z | y) leads to an iterative algorithm to calculate p($\theta$ | y). Analytically, this algorithm is essentially the method of successive substitution for solving an operator fixed point equation. We exploit this fact to prove convergence under mild regularity conditions. Typically, to implement the algorithm, one must be able to sample from two distributions, namely p($\theta$ | y, z) and p(z | $\theta$, y). In many cases, it is straightforward to sample from either distribution. In general, though, either sampling can be difficult, just as either the E or the M step can be difficult to implement in the EM algorithm. For p($\theta$ | y, z) arising from parametric submodels of the multinomial, we develop a primitive but generally applicable way to approximately sample $\theta$. The idea is first to sample from the posterior distribution of the cell probabilities and then to project to the parametric surface that is specified by the submodel, giving more weight to those observations lying closer to the surface. This procedure should cover many of the common models for categorical data. There are several examples given in this article. First, the algorithm is introduced and motivated in the context of a genetic linkage example. Second, we apply this algorithm to an example of inference from incomplete data regarding the correlation coefficient of the bivariate normal distribution. It is seen that the algorithm recovers the bimodal nature of the posterior distribution. Finally, the algorithm is used in the analysis of the traditional latent-class model as applied to data from the General Social Survey.},
	number = {398},
	urldate = {2020-12-28},
	journal = {Journal of the American Statistical Association},
	author = {Tanner, Martin A. and Wong, Wing Hung},
	year = {1987},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {528--540}
}

@article{swendsenNonuniversalCriticalDynamics1987a,
	title = {Nonuniversal critical dynamics in {Monte} {Carlo} simulations},
	volume = {58},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.58.86},
	doi = {10.1103/PhysRevLett.58.86},
	abstract = {A new approach to Monte Carlo simulations is presented, giving a highly efficient method of simulation for large systems near criticality. The algorithm violates dynamic universality at second-order phase transitions, producing unusually small values of the dynamical critical exponent.},
	number = {2},
	urldate = {2020-12-28},
	journal = {Physical Review Letters},
	author = {Swendsen, Robert H. and Wang, Jian-Sheng},
	month = jan,
	year = {1987},
	note = {publisher: American Physical Society},
	pages = {86--88}
}

@article{choiPolyaGammaGibbsSampler2013,
	title = {The {Polya}-{Gamma} {Gibbs} sampler for {Bayesian} logistic regression is uniformly ergodic},
	volume = {7},
	issn = {1935-7524},
	url = {http://projecteuclid.org/euclid.ejs/1377005819},
	doi = {10.1214/13-EJS837},
	abstract = {One of the most widely used data augmentation algorithms is Albert and Chib{\textquoteright}s (1993) algorithm for Bayesian probit regression. Polson, Scott, and Windle (2013) recently introduced an analogous algorithm for Bayesian logistic regression. The main difference between the two is that Albert and Chib{\textquoteright}s (1993) truncated normals are replaced by so-called Polya-Gamma random variables. In this note, we establish that the Markov chain underlying Polson, Scott, and Windle{\textquoteright}s (2013) algorithm is uniformly ergodic. This theoretical result has important practical benefits. In particular, it guarantees the existence of central limit theorems that can be used to make an informed decision about how long the simulation should be run.},
	language = {EN},
	urldate = {2020-12-28},
	journal = {Electronic Journal of Statistics},
	author = {Choi, Hee Min and Hobert, James P.},
	year = {2013},
	mrnumber = {MR3091616},
	zmnumber = {1349.60123},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {data augmentation algorithm, Markov chain, minorization condition, Monte Carlo, Polya-Gamma distribution},
	pages = {2054--2064}
}

@article{choiComparisonTheoremData2016,
	title = {A comparison theorem for data augmentation algorithms with applications},
	volume = {10},
	issn = {1935-7524},
	url = {https://projecteuclid.org/euclid.ejs/1455715964},
	doi = {10.1214/16-EJS1106},
	abstract = {The data augmentation (DA) algorithm is considered a useful Markov chain Monte Carlo algorithm that sometimes suffers from slow convergence. It is often possible to convert a DA algorithm into a sandwich algorithm that is computationally equivalent to the DA algorithm, but converges much faster. Theoretically, the reversible Markov chain that drives the sandwich algorithm is at least as good as the corresponding DA chain in terms of performance in the central limit theorem and in the operator norm sense. In this paper, we use the sandwich machinery to compare two DA algorithms. In particular, we provide conditions under which one DA chain can be represented as a sandwich version of the other. Our results are used to extend Hobert and Marchev{\textquoteright}s (2008) results on the Haar PX-DA algorithm and to improve the collapsing theorem of Liu et al. (1994) and Liu (1994). We also illustrate our results using Brownlee{\textquoteright}s (1965) stack loss data.},
	language = {EN},
	number = {1},
	journal = {Electronic Journal of Statistics},
	author = {Choi, Hee Min and Hobert, James P.},
	year = {2016},
	mrnumber = {MR3466184},
	zmnumber = {1338.60189},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {central limit theorem, convergence rate, Data augmentation algorithm, operator norm, sandwich algorithm},
	pages = {308--329}
}

@phdthesis{choiConvergenceAnalysisGibbs2014,
	address = {United States -- Florida},
	type = {Ph.{D}.},
	title = {Convergence analysis of {Gibbs} samplers for {Bayesian} regression models},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {http://search.proquest.com/docview/1727735455/abstract/9DD422F654E3470DPQ/1},
	abstract = {We study the convergence rates of the Markov chains underlying Markov chain Monte Carlo (MCMC) algorithms associated with two widely used Bayesian regression models. First, we analyze Polson, Scott, \& Windle{\textquoteright}s (2013) data augmentation (DA) algorithm for exploring the intractable posterior density that results when the logistic likelihood is combined with normal prior. It is established that the corresponding Markov chain is uniformly ergodic. Second, we analyze the Markov chains underlying DA and Haar PX-DA algorithms for the intractable posterior density that results when the standard default prior is placed on the parameters in a linear regression model with Laplace errors. In particular, we establish that the Markov chains underlying the two algorithms are geometrically ergodic. It is also shown that the Haar PX-DA algorithm converges at least as fast as the DA algorithm.
The convergence rate results developed in this dissertation are important because they are key sufficient conditions for the honest MCMC estimation for the posterior expectations associated with the two Bayesian regression models. By honest MCMC estimation, we mean the MCMC estimates are reported along with an asymptotically valid standard error, and there is an informed decision strategy for determining how long the MCMC simulation should be run. To describe how to carry out an honest estimation procedure, we use a real data set on shuttle O-ring thermal-distress for the Bayesian logistic regression model.
We discuss a slightly different topic in the final chapter. When using the MCMC method for exploring an intractable density $\pi$, one is free to choose any MCMC algorithm that has invariant density $\pi$. Obviously, different algorithms have different performance in terms of convergence and efficiency. We carefully address this issue when we use particular MCMC algorithms, general PX-DA and Haar PX-DA algorithms. In particular, we establish that general Haar PX-DA is at least as good as general PX-DA in the efficiency ordering and operator norm sense.},
	language = {English},
	school = {University of Florida},
	author = {Choi, Hee Min},
	year = {2014},
	note = {ISBN: 9781339148977},
	keywords = {Bayesian, Convergence, Markov chain Monte Carlo, Pure sciences, Regression}
}

@book{doksumMathematicalStatisticsBasic2015,
	title = {Mathematical {Statistics} : {Basic} {Ideas} and {Selected} {Topics}, {Volumes} {I}-{II} {Package}},
	isbn = {978-1-315-36926-6},
	shorttitle = {Mathematical {Statistics}},
	url = {https://www.taylorfrancis.com/books/mathematical-statistics-peter-bickel-kjell-doksum/10.1201/9781315369266},
	abstract = {Volume I presents fundamental, classical statistical concepts at the doctorate level without using measure theory. It gives careful proofs of major results},
	language = {en},
	publisher = {Chapman and Hall/CRC},
	author = {Doksum, Kjell A.},
	month = dec,
	year = {2015},
	doi = {10.1201/9781315369266}
}


@book{casellaStatisticalInference2002,
	address = {Australia ; Pacific Grove, CA},
	edition = {2nd ed},
	title = {Statistical inference},
	isbn = {978-0-534-24312-8},
	publisher = {Thomson Learning},
	author = {Casella, George and Berger, Roger L.},
	year = {2002},
	keywords = {Mathematical statistics, Probabilities}
}


@article{dempsterMaximumLikelihoodIncomplete1977,
	title = {Maximum {Likelihood} from {Incomplete} {Data} {Via} the {EM} {Algorithm}},
	volume = {39},
	copyright = {{\textcopyright} 1977 The Authors},
	issn = {2517-6161},
	doi = {https://doi.org/10.1111/j.2517-6161.1977.tb01600.x},
	abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
	language = {en},
	number = {1},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
	year = {1977},
	keywords = {em algorithm, incomplete data, maximum likelihood, posterior mode},
	pages = {1--22}
}

@article{mengSeekingEfficientData1999,
	title = {Seeking efficient data augmentation schemes via conditional and marginal augmentation},
	volume = {86},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/86.2.301},
	doi = {10.1093/biomet/86.2.301},
	abstract = {Data augmentation, sometimes known as the method of auxiliary variables, is a powerful tool for constructing optimisation and simulation algorithms. In the context of optimisation, Meng \&amp; van Dyk (1997, 1998) reported several successes of the 'working parameter' approach for constructing efficient data-augmentation schemes for fast and simple EM-type algorithms. This paper investigates the use of working parameters in the context of Markov chain Monte Carlo, in particular in the context of Tanner \&amp; Wong's (1987) data augmentation algorithm, via a theoretical study of two working-parameter approaches, the conditional augmentation approach and the marginal augmentation approach. Posterior sampling under the univariate t model is used as a running example, which particularly illustrates how the marginal augmentation approach obtains a fast-mixing positive recurrent Markov chain by first constructing a nonpositive recurrent Markov chain in a larger space.},
	number = {2},
	journal = {Biometrika},
	author = {Meng, X-L and van Dyk, DA},
	month = jun,
	year = {1999},
	pages = {301--320}
}

@article{dykCrossFertilizingStrategiesBetter2010,
	title = {Cross-{Fertilizing} {Strategies} for {Better} {EM} {Mountain} {Climbing} and {DA} {Field} {Exploration}: {A} {Graphical} {Guide} {Book}},
	volume = {25},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Cross-{Fertilizing} {Strategies} for {Better} {EM} {Mountain} {Climbing} and {DA} {Field} {Exploration}},
	url = {http://projecteuclid.org/euclid.ss/1300108229},
	doi = {10.1214/09-STS309},
	abstract = {In recent years, a variety of extensions and refinements have been developed for data augmentation based model fitting routines. These developments aim to extend the application, improve the speed and/or simplify the implementation of data augmentation methods, such as the deterministic EM algorithm for mode finding and stochastic Gibbs sampler and other auxiliary-variable based methods for posterior sampling. In this overview article we graphically illustrate and compare a number of these extensions, all of which aim to maintain the simplicity and computation stability of their predecessors. We particularly emphasize the usefulness of identifying similarities between the deterministic and stochastic counterparts as we seek more efficient computational strategies. We also demonstrate the applicability of data augmentation methods for handling complex models with highly hierarchical structure, using a high-energy high-resolution spectral imaging model for data from satellite telescopes, such as the Chandra X-ray Observatory.},
	language = {EN},
	number = {4},
	journal = {Statistical Science},
	author = {Dyk, David A. van and Meng, Xiao-Li},
	month = nov,
	year = {2010},
	mrnumber = {MR2807762},
	zmnumber = {1329.62040},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {AECM, blocking, collapsing, conditional augmentation, data augmentation, ECM, ECME, efficient augmentation, Gibbs Sampling, marginal augmentation, model reduction, NEM, nesting},
	pages = {429--449}
}


@article{shortenSurveyImageData2019,
	title = {A survey on {Image} {Data} {Augmentation} for {Deep} {Learning}},
	volume = {6},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	number = {1},
	journal = {Journal of Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	month = jul,
	year = {2019},
	keywords = {Big data, Data Augmentation, Deep Learning, GANs, Image data},
	pages = {60}
}


@article{nealSliceSampling2003,
	title = {Slice {Sampling}},
	volume = {31},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/3448413},
	abstract = {Markov chain sampling methods that adapt to characteristics of the distribution being sampled can be constructed using the principle that one can sample from a distribution by sampling uniformly from the region under the plot of its density function. A Markov chain that converges to this uniform distribution can be constructed by alternating uniform sampling in the vertical direction with uniform sampling from the horizontal "slice" defined by the current vertical position, or more generally, with some update that leaves the uniform distribution over this slice invariant. Such "slice sampling" methods are easily implemented for univariate distributions, and can be used to sample from a multivariate distribution by updating each variable in turn. This approach is often easier to implement than Gibbs sampling and more efficient than simple Metropolis updates, due to the ability of slice sampling to adaptively choose the magnitude of changes made. It is therefore attractive for routine and automated use. Slice sampling methods that update all variables simultaneously are also possible. These methods can adaptively choose the magnitudes of changes made to each variable, based on the local properties of the density function. More ambitiously, such methods could potentially adapt to the dependencies between variables by constructing local quadratic approximations. Another approach is to improve sampling efficiency by suppressing random walks. This can be done for univariate slice sampling by "overrelaxation," and for multivariate slice sampling by "reflection" from the edges of the slice.},
	number = {3},
	journal = {The Annals of Statistics},
	author = {Neal, Radford M.},
	year = {2003},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {705--741}
}


@article{piegorschEmpiricalBayesEstimation1996,
	title = {Empirical {Bayes} {Estimation} for {Logistic} {Regression} and {Extended} {Parametric} {Regression} {Models}},
	volume = {1},
	issn = {1085-7117},
	url = {http://www.jstor.org/stable/1400367},
	doi = {10.2307/1400367},
	abstract = {Parametric empirical Bayes methods are discussed for estimating the mean proportion response from generalized linear regression models (GLiM's) based on the binomial distribution, including the well-known case of logistic regression. The GLiM's are extended via parametric families of link functions that embed specific links--such as the logit--within their parametric structure. The models may be viewed as members of a larger class of conditionally independent hierarchical models. An example from environmental mutagenesis, wherein a hierarchical effect is induced by similarities among responding units, motivates consideration of the hierarchical GLiM. Empirical Bayes estimation of the mean proportion response is addressed for this example, with emphasis directed at extensions of the logit model.},
	number = {2},
	journal = {Journal of Agricultural, Biological, and Environmental Statistics},
	author = {Piegorsch, Walter W. and Casella, George},
	year = {1996},
	note = {Publisher: [International Biometric Society, Springer]},
	pages = {231--249}
}

@article{greenlandPuttingBackgroundInformation2001,
	title = {Putting {Background} {Information} about {Relative} {Risks} into {Conjugate} {Prior} {Distributions}},
	volume = {57},
	issn = {0006-341X},
	url = {http://www.jstor.org/stable/3068401},
	abstract = {In Bayesian and empirical Bayes analyses of epidemiologic data, the most easily implemented prior specifications use a multivariate normal distribution for the log relative risks or a conjugate distribution for the discrete response vector. This article describes problems in translating background information about relative risks into conjugate priors and a solution. Traditionally, conjugate priors have been specified through flattening constants, an approach that leads to conflicts with the true prior covariance structure for the log relative risks. One can, however, derive a conjugate prior consistent with that structure by using a data-augmentation approximation to the true log relative-risk prior, although a rescaling step is needed to ensure the accuracy of the approximation. These points are illustrated with a logistic regression analysis of neonatal-death risk.},
	number = {3},
	journal = {Biometrics},
	author = {Greenland, Sander},
	year = {2001},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {663--670}
}


@article{zellnerBayesianAnalysisDichotomous1984,
	title = {Bayesian analysis of dichotomous quantal response models},
	volume = {25},
	issn = {0304-4076},
	url = {http://www.sciencedirect.com/science/article/pii/0304407684900071},
	doi = {10.1016/0304-4076(84)90007-1},
	abstract = {Qualitative response models (QRM's) are analyzed from the Bayesian point of view, using diffuse and informative prior distributions. Exact finite-sample Bayesian and large-sample Bayesian and non-Bayesian estimation results are compared. In addition, the paper provides: (1) plots and discussion of the properties of likelihood functions for QRM's, (2) posterior distributions for logit models' derivatives and elasticities, (3) Bayesian prediction procedures for QRM's, (4) new estimates for the median and other fractiles of the logistic distribution, (5) posterior odds ratios for model selection problems, and (6) comparisons of two alternative Monte Carlo numerical integration procedures. It is concluded that asymptotic approximations are not accurate for small-to moderate-sized samples even when only a single input variable is used, and that operational Bayesian methods are available for providing both exact small-sample and large-sample approximate inferences for DRM's.},
	language = {en},
	number = {3},
	journal = {Journal of Econometrics},
	author = {Zellner, Arnold and Rossi, Peter E},
	month = jul,
	year = {1984},
	pages = {365--393}
}

@article{gelfandSamplingBasedApproachesCalculating1990,
	title = {Sampling-{Based} {Approaches} to {Calculating} {Marginal} {Densities}},
	volume = {85},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2289776},
	doi = {10.2307/2289776},
	abstract = {Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated.},
	number = {410},
	journal = {Journal of the American Statistical Association},
	author = {Gelfand, Alan E. and Smith, Adrian F. M.},
	year = {1990},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {398--409}
}

@book{ohaganKendallAdvancedTheory2004,
	title = {Kendall's {Advanced} {Theory} of {Statistics}, volume {2B}: {Bayesian} {Inference}, second edition},
	volume = {2B},
	isbn = {978-0-340-80752-1},
	shorttitle = {Kendall's {Advanced} {Theory} of {Statistics}, volume {2B}},
	url = {https://eprints.soton.ac.uk/46376/},
	publisher = {Arnold},
	author = {O'Hagan, Anthony and Forster, Jonathan J.},
	year = {2004}
}

@article{tierneyMarkovChainsExploring1994,
	title = {Markov {Chains} for {Exploring} {Posterior} {Distributions}},
	volume = {22},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/2242477},
	abstract = {Several Markov chain methods are available for sampling from a posterior distribution. Two important examples are the Gibbs sampler and the Metropolis algorithm. In addition, several strategies are available for constructing hybrid algorithms. This paper outlines some of the basic methods and strategies and discusses some related theoretical and practical issues. On the theoretical side, results from the theory of general state space Markov chains can be used to obtain convergence rates, laws of large numbers and central limit theorems for estimates obtained from Markov chain methods. These theoretical results can be used to guide the construction of more efficient algorithms. For the practical use of Markov chain methods, standard simulation methodology provides several variance reduction techniques and also give guidance on the choice of sample size and allocation.},
	number = {4},
	journal = {The Annals of Statistics},
	author = {Tierney, Luke},
	year = {1994},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1701--1728}
}


@article{choiAnalysisPolyaGammaGibbs2017,
	title = {Analysis of {Polya}-{Gamma} {Gibbs} sampler for {Bayesian} logistic analysis of variance},
	volume = {11},
	issn = {1935-7524},
	url = {http://projecteuclid.org/euclid.ejs/1486458017},
	doi = {10.1214/17-EJS1227},
	abstract = {We consider the intractable posterior density that results when the one-way logistic analysis of variance model is combined with a flat prior. We analyze Polson, Scott and Windle{\textquoteright}s (2013) data augmentation (DA) algorithm for exploring the posterior. The Markov operator associated with the DA algorithm is shown to be trace-class.},
	language = {EN},
	number = {1},
	journal = {Electronic Journal of Statistics},
	author = {Choi, Hee Min and Rom{\'a}n, Jorge Carlos},
	year = {2017},
	mrnumber = {MR3606773},
	zmnumber = {1356.60117},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {data augmentation algorithm, geometric convergence rate, Markov chain, Markov operator, Monte Carlo, Polya-Gamma distribution, trace-class operator},
	pages = {326--337}
}


@article{agrestiBayesianInferenceCategorical2005,
	title = {Bayesian inference for categorical data analysis},
	volume = {14},
	issn = {1613-981X},
	url = {https://doi.org/10.1007/s10260-005-0121-y},
	doi = {10.1007/s10260-005-0121-y},
	abstract = {This article surveys Bayesian methods for categorical data analysis, with primary emphasis on contingency table analysis. Early innovations were proposed by Good (1953, 1956, 1965) for smoothing proportions in contingency tables and by Lindley (1964) for inference about odds ratios. These approaches primarily used conjugate beta and Dirichlet priors. Altham (1969, 1971) presented Bayesian analogs of small-sample frequentist tests for 2 x 2 tables using such priors. An alternative approach using normal priors for logits received considerable attention in the 1970s by Leonard and others (e.g., Leonard 1972). Adopted usually in a hierarchical form, the logit-normal approach allows greater flexibility and scope for generalization. The 1970s also saw considerable interest in loglinear modeling. The advent of modern computational methods since the mid-1980s has led to a growing literature on fully Bayesian analyses with models for categorical data, with main emphasis on generalized linear models such as logistic regression for binary and multi-category response variables.},
	language = {en},
	number = {3},
	journal = {Statistical Methods and Applications},
	author = {Agresti, Alan and Hitchcock, David B.},
	month = dec,
	year = {2005},
	pages = {297--330}
}

@book{agrestiCategoricalDataAnalysis2012,
	address = {Somerset, UNITED STATES},
	title = {Categorical {Data} {Analysis}},
	isbn = {978-1-118-71094-4},
	url = {http://ebookcentral.proquest.com/lib/psu/detail.action?docID=1168529},
	abstract = {Praise for the Second Edition "A must-have book for anyone expecting to do research and/or applications in categorical data analysis." --Statistics in Medicine "It is a total delight reading this book." --Pharmaceutical Research "If you do any analysis of categorical data, this is an essential desktop reference." --Technometrics The use of statistical methods for analyzing categorical data has increased dramatically, particularly in the biomedical, social sciences, and financial industries. Responding to new developments, this book offers a comprehensive treatment of the most important methods for categorical data analysis. Categorical Data Analysis, Third Edition summarizes the latest methods for univariate and correlated multivariate categorical responses. Readers will find a unified generalized linear models approach that connects logistic regression and Poisson and negative binomial loglinear models for discrete data with normal regression for continuous data. This edition also features: An emphasis on logistic and probit regression methods for binary, ordinal, and nominal responses for independent observations and for clustered data with marginal models and random effects models Two new chapters on alternative methods for binary response data, including smoothing and regularization methods, classification methods such as linear discriminant analysis and classification trees, and cluster analysis New sections introducing the Bayesian approach for methods in that chapter More than 100 analyses of data sets and over 600 exercises Notes at the end of each chapter that provide references to recent research and topics not covered in the text, linked to a bibliography of more than 1,200 sources A supplementary website showing how to use R and SAS; for all examples in the text, with information also about SPSS and Stata and with exercise solutions Categorical Data Analysis, Third Edition is an invaluable tool for statisticians and methodologists, such as biostatisticians and researchers in the social and behavioral sciences, medicine and public health, marketing, education, finance, biological and agricultural sciences, and industrial quality control.},
	publisher = {John Wiley \& Sons, Incorporated},
	author = {Agresti, Alan},
	year = {2012},
	keywords = {Mathematical statistics., Multivariate analysis -- Data processing., Multivariate analysis.}
}

@book{mclachlanEMAlgorithmExtensions2008,
	title = {The {EM} {Algorithm} and {Extensions}},
	isbn = {978-0-470-19160-6 978-0-470-19161-3 978-0-471-20170-0},
	url = {https://nbn-resolving.org/urn:nbn:de:101:1-201411014724},
	language = {English},
	urldate = {2021-01-03},
	author = {McLachlan, Geoffrey and Krishnan, Thriyambakam},
	year = {2008},
	note = {OCLC: 845575460}
}

@book{tannerToolsStatisticalInference1993,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Tools for {Statistical} {Inference}},
	isbn = {978-1-4684-0194-3 978-1-4684-0192-9},
	url = {http://link.springer.com/10.1007/978-1-4684-0192-9},
	publisher = {Springer US},
	author = {Tanner, Martin A.},
	year = {1993},
	doi = {10.1007/978-1-4684-0192-9}
}

