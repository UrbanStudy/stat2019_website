% Fact sheet for MATH 300, for Fall 2014.
%
\documentclass[11pt]{article}
% Nice page size.
\setlength{\textwidth}{7in} \setlength{\textheight}{9.8in}
\setlength{\topmargin}{-1in} \setlength{\oddsidemargin}{-0.25in}
\setlength{\evensidemargin}{-0.25in}
%
% No page numbering.
\pagestyle{empty}
\usepackage{graphicx}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\usepackage{color}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{algpseudocode}
\begin{document}
\thispagestyle{empty}
\includegraphics{../../../psulogo_horiz_bw.eps}\hfill\includegraphics{../../../deptlogo}
\vspace{10pt}
\begin{center}
{\large\bf STAT 671}    \\*[5pt] {\Large Statistical Learning I}
\\*[12pt] {\large Fall 2019}
\\ {\large Homework 2}
\\ {\large Due October 28$^{th}$ at the beginning of class}
\end{center}
\vspace{1cm}
\noindent

%\section{Kernalized ridge regression}
%\begin{enumerate}
%\item Code the kernalized ridge regression for the 2d example that you already used for the simple classifier and the perceptron. Show your code.  
%\item Show 3 examples of results obtain with simulated data in 2 dimensions, using 3 different kernels. 
%\end{enumerate}
%\section{MNIST dataset}
%\begin{enumerate}
%\item Import the MNIST dataset. It is available on D2L. A R file is available for reading the files and run a simple classifier.  you will find online similar code in case you use Matlab or other high level language. 
%\item Try to run the kernelized ridge regression for the digit zero versus all the other ones.  You will see that the size of the training set is too large. Sample a smaller training set, say of size 100. Now, you should be able to run it. Experiment with larger training set size. Report the performances, learning time and testing time on a graph.   
%\end{enumerate}
\section{Kernels}
\begin{enumerate}
\item let $(x,y) \in \mathbb{R}^+ \times \mathbb{R}^+$, where $\mathbb{R}^+=\{x \in \mathbb{R};x \geq 0\}$, the ``french positive\rq\rq{} real numbers. 
\begin{enumerate}
\item 
Verify that 
$$\min(x,y) = \int_0^\infty \mathbb{I}_{t\leq x} \mathbb{I}_{t\leq y} dt$$
where  
$$\mathbb{I}_A =  \left\{
\begin{tabular}{ll}
1 & \mbox{ if A is true}\\
0 & \mbox{otherwise}
\end{tabular}
\right.
$$ 

\item Use the previous question to show that $K(x,y)=\min(x,y)$ is a pd kernel over $\mathbb{R}^+$
\item Show that $\max(x,y)$ is not a pd kernel over  $\mathbb{R}^+$. 
\end{enumerate}
\item Consider a probability space $(\Omega,\mathcal{A},P)$
\begin{enumerate}
\item Define for any two events $A$ and $B$, 
$$K_1(A,B)=P(A \cap B)$$
where $A \cap B$ is the intersection between the events A and B 
Verify that $K_1$ is positive definite. Hint: $P(A)=E[\mathbb{I}_A]$
\item Define for any two events $A$ and $B$, 
$$K_2(A,B)=P(A \cap B)-P(A)P(B)$$
Verify that $K_2$ is positive definite. 
\end{enumerate}
\end{enumerate}
\section{Kernels and RKHS}
\begin{enumerate}
\item Define the RKHS  over $\mathbb{R}^d$
$$K(x,y)=x^Ty+c$$
where $c>0$. 
\begin{enumerate}
\item
What is the RKHS associated with the kernel $K$? no proof is required. 
\item 
What is the inner product in this RKHS? no proof required.  
\item 
Verify the reproducing property
\end{enumerate}
\item Define the RKHS  over $\mathbb{R}^d$
$$K(x,y)=(x^Ty)^2$$
where $c>0$. 
The RKHS associated with the kernel $K$ is $\{f_S;f_S(x)=x^T S x\}$ where $S$ is a symmetric $(d,d)$ matrix. The inner product is
$$<f_{S_1},f_{S_2}>=<S_1,S_2>_F$$
\begin{enumerate}
\item
Verify the reproducing property. 
\item 
Why do we require that $S$ is symmetric?
\end{enumerate}
\item Define the RKHS  over $\mathbb{R}^d$
$$K(x,y)=(x^Ty+c)^2$$
where $c>0$. 
\begin{enumerate}
\item
What is the RKHS associated with the kernel $K$? no proof is required. 
\item 
What is the inner product in this RKHS? no proof required.  
\item 
Verify the reproducing property
\end{enumerate}
\end{enumerate}
\section{Fisher kernel} 
Let\footnote{If you are not familiar with probabilistic models, do not panic! come to see me.} $\theta \in \mathbb{R}$ be a parameter and let $p_\theta$ be a probabilistic model (i.e a point mass function or a density) over a set $\mathcal{X}$ indexed by $\theta$. Let $\theta_0 \in \mathbb{R}$ be a specific value for $\theta$.

Let us define the Fisher score at $x \in \mathcal{X}$ as
\begin{equation}
\phi(x,\theta_0) = \frac{\delta}{\delta \theta} \ln p_\theta(x) \mbox{ evaluated at } \theta=\theta_0
\end{equation}
assuming that this quantity exists. 

Define $I(\theta)$, the Fisher information associated with the parameter $\theta$, i.e., 
\begin{equation}
I(\theta)=E[\phi^2(X,\theta)]
\end{equation}
where $E$ stands for expectation and $X$ is a random variable with distribution $p_\theta$. 

The Fisher kernel is then 
\begin{equation}
k(x,x')=\frac{\phi(x,\theta_0)\phi(x',\theta_0)}{I(\theta_0)}
\end{equation}
where 
\begin{enumerate}
\item Verify that $k(.,.)$ is a positive definite kernel over $\mathcal{X}$
\item Consider the following model: $x \in \{0,1\}$, $X \sim Bernoulli(\theta)$, $0 < \theta < 1$, that is
\begin{equation}
p_\theta(x)=\theta^x(1-\theta)^{(1-x)} 
\end{equation}
We recall that in this case $E[X]=\theta$ and $Var[X]=E[(X-\theta)^2]=\theta(1-\theta)$

Compute $k(x,x')$

Hint: you will find $$k(x,x')=\frac{(x-\theta_0)(x'-\theta_0)}{\theta_0(1-\theta_0)}$$
\item
Assume now $x=(x_1,x_2)$ with $x_1 \in \{0,1\}$ and $x_2 \in \{0,1\}$. 
We consider the following model where $X=(X_1,X_2)$, $X_1$ and $X_2$ are independent with the same $Bernoulli(\theta)$ distribution. 
Compute $k(x,x')$. 
\end{enumerate}
 


 


\end{document}
