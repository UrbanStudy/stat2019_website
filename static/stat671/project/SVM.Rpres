STAT 671: Statistical Learning

Support Vector Machines
========================================================
author: Di &Shen
date: Dec, 2019
autosize: true
font-family: 'Helvetica'
1. Introduction
2. Support Vector Classifiers - Linear Kernels
3. Polynomial Kernels
4. Radial Basis Function Kernels


Introduction
========================================================

1. Identifying decision boundaries

2. Find the maximal margin separator

3. Generating a linearly separable dataset

4. Generate a 2d uniformly distributed dataset.

5. Create a decision boundary

6. Introduce a margin in the dataset

Visualizing
========================================================

- a 1-dimensional scatter plot of 25 soft drink sugar content measurements. 
 
- visualize distinct clusters in the dataset as a first step towards identifying candidate decision boundaries.

```{r, echo=F}
# Create the data frame.
sugar <- data.frame(
   sugar_sample = as.factor(c (1:25)),
   sugar_content=c(10.9,10.9,10.6,10.0,8.0,8.2,8.6,10.9,10.7,8.0,7.7,7.8,8.4,11.5,11.2,8.9,8.7,7.4,10.9,10.0,11.4,10.8,8.5,8.2,10.6)
)
library(ggplot2)
ggplot(data =sugar, aes(x = sugar_sample, y = sugar_content)) + 
    geom_point() + theme_light()+
    geom_text(aes(label = sugar_content), size = 2.5, vjust = 2, hjust = 0.5)
```

Support Vector Classifiers - Linear Kernels
========================================================


# Polynomial Kernels


# Radial Basis Function Kernels