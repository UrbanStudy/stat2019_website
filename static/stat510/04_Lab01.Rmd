---
title: 'STAT 510: Spatiotemporal Stats'
author: "Prof. Taylor-Rodriguez"
subtitle: Spatiotemporal Stats Lab 1
output:
  html_notebook: default
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, echo=T, message=F, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache = TRUE)
library(STRbook)
library(ggplot2)
library(dplyr)
library(tidyr)
library(tidyverse)
library(sp)
library(spacetime)
library(lubridate)
```


## Let's get the Lab started

We'll be working with the following datasets

1. *Station.dat*: ($328\times 3$) station info

2. *Times_1990.dat*: ($1461\times 4$) daily time stamps between Jan 1st 1990 and Dec 30 1993

3. *Tmax_1990.dat*: ($1461\times 328$) Daily Tmax by station (NA's$\equiv -9999$)

4. *Tmin_1990.dat*: ($1461\times 328$) Daily Tmin by station (NA's$\equiv -9999$)

5. *Precip_1990.dat*: ($1461\times 328$) Daily Precip by station (NA's$\equiv -9999.90001$)

6. *Precip_1990.dat*: ($1461\times 328$) Daily Precip by station (NA's$\equiv -9999.989998$)

# Data Wrangling

## Data Wrangling and Visualization

First, let's load into R, combine and rearrange into long format these datasets. 

\bigskip
This can help summarize and visualize the data


## Loading data tables into R

\scriptsize
```{r}
#locations
locs <- read.table(system.file("extdata","Stationinfo.dat",
                               package = "STRbook"),
                   col.names = c("id", "lat", "lon"))

#times
Times <- read.table(system.file("extdata","Times_1990.dat",
                                package = "STRbook"),
                    col.names = c("julian", "year", "month", "day"))

#Actual data files
Tmax <- read.table(system.file("extdata", "Tmax_1990.dat",
                               package = "STRbook"))
Tmin <- read.table(system.file("extdata", "Tmin_1990.dat",
                               package = "STRbook"))
Precip <- read.table(system.file("extdata", "Precip_1990.dat",
                               package = "STRbook"))

#name columns (station id's) in data tables
names(Tmax) <- names(Tmin) <- names(Precip) <- locs$id
```


## Convert data into long format

\scriptsize
```{r}
#using dplyr functions:
Tmax_long <- bind_cols(Times,Tmax) %>% #add time stamps to Tmax
  gather(key="id", value="values",  
         -julian, -year, -month, -day) %>% #make into long format
  mutate(proc="Tmax") #add variable label

head(Tmax_long,4)
```
\textcolor{red}{Note:} the `gather` function has been replaced by `pivot_long`... but for now we'll stick to what they use in the book


## Convert data into long format

\scriptsize

```{r}
#rinse and repeat with Tmin and Precip
Tmin_long <- bind_cols(Times,Tmin) %>%
  gather(key="id", value="values", -julian, -year, -month, -day) %>% 
  mutate(proc="Tmin") 

Precip_long <- bind_cols(Times,Precip) %>%
  gather(key="id", value="values", -julian, -year,
         -month, -day)  %>% 
  mutate(proc="Precip")
```

## Combine data and remove NA's

\scriptsize
```{r}
#combine all data into single
NOAA_df_1990 <- bind_rows(Tmax_long,
                          Tmin_long,
                          Precip_long)
#remove NA's
NOAA_df_1990 <- NOAA_df_1990 %>% 
  filter(values>-9999 & (proc%in%c("Tmax","Tmin")) |
           values>-99 & proc=="Precip")
#remove previous datasets
rm(list=c("Tmax_long","Tmin_long","Precip_long"))
```

## Some simple data summaries

\scriptsize
```{r warning=F,message=F}
#overall means by variable ("proc" in data)
summ <- NOAA_df_1990 %>% 
  group_by(proc) %>% 
  summarise(proc_means=mean(values))
head(summ)
```

## Some simple data summaries

\scriptsize
```{r warning=F,message=F}
#yearly means by variable
summ <- NOAA_df_1990 %>% 
  group_by(proc,year) %>% 
  summarise(proc_means=mean(values))
head(summ,5)
```


## More involved summaries

### Mean number of dry days in June each year by station

\scriptsize
```{r warning=F,message=F}
summ <- NOAA_df_1990 %>% 
  filter(proc=="Precip",month==6,values==0) %>% 
  group_by(id,year,month) %>% 
  summarise(numdry=n())
head(summ)
```

## More involved summaries

### Mean number of dry days in June each year

\scriptsize
```{r warning=F,message=F}
summ <- summ %>% 
  ungroup() %>% 
  group_by(year,month) %>% 
  summarise(mu_noprecip=mean(numdry)) %>% 
  select(-month)
head(summ)
```


## Combining datasets using *keys*

Let's add the station location information to the combined data

\scriptsize
```{r warning=F,message=F}
locs <- locs %>% mutate(id=as.character(id))
NOAA_df_1990 <- NOAA_df_1990 %>% 
  left_join(locs,by="id")

head(NOAA_df_1990,5)
```

\textcolor{red}{Note:} `left_join` keeps all observations in left dataset and finds matches according to the *key* (here *"id"*) in the dataset on the right hand side. Other options available.

## Create *date* variable from *year*, *month*, *day*

Let's add the station location information to the combined data

\scriptsize
```{r warning=F,message=F}
NOAA_df_1990 <- NOAA_df_1990 %>% 
  unite("date",year,month,day,remove=F) %>% 
  mutate(date=ymd(date))

head(NOAA_df_1990,5)
```




# Visualization



## Empirical Spatial Means Plot

### For geostatistical data

\scriptsize
```{r echo=T, eval=T, message=F, fig.height=2.5, fig.width=3, fig.align='center'}
NOAA_df_1990 %>% 
  filter(proc=="Tmax") %>% 
  group_by(id,lon,lat) %>%
  summarise(z=mean(values)) %>% 
  ggplot() + 
  geom_point(aes(x=lon,y=lat,colour=z),size=2) +
  col_scale(name = "degF") + 
  xlab("Longitude (deg)") + 
  ylab("Latitude (deg)") + 
  geom_path(data = map_data("state"),# state boundaries
            aes(x = long, y = lat, group = group)) +
  coord_fixed(xlim = c(-105, -75),
              ylim= c(25,50)) +
  theme_bw()
```



## Empirical Spatial Means Plot (By Year)

### For geostatistical data

\scriptsize
```{r echo=T, eval=T, message=F, fig.height=5, fig.width=5, fig.align='center'}
NOAA_df_1990 %>% 
  filter(proc=="Tmax") %>% 
  group_by(id,lon,lat,year) %>%
  summarise(z=mean(values)) %>% 
  ggplot() + 
  geom_point(aes(x=lon,y=lat,colour=z),size=0.5) +
  col_scale(name = "degF") + 
  xlab("Longitude (deg)") + 
  ylab("Latitude (deg)") + 
  geom_path(data = map_data("state"),# state boundaries
            aes(x = long, y = lat, group = group)) +
#  facet_grid(.~year) + #,rows=2,cols=2
  facet_wrap(.~year,nrow=2,ncol=2) + #
  coord_fixed(xlim = c(-105, -75),
              ylim= c(25,50)) +
  theme_bw()
```


## Empirical Spatial Covariances and Plots

### For geostatistical data

Let's work with the Tmax data between May and September of 1993
\scriptsize
```{r echo=T, eval=T, message=F}
Tmax_long <- NOAA_df_1990 %>% # now subset the data
  filter(proc == "Tmax" &     # only max temperature
           month %in% 5:9 &   # May to September
           year == 1993) %>%  # year 1993
  mutate(t=as.integer(julian-min(julian-1))) #create time variable
```


## Empirical Spatial Covariances and Plots

But first, de-trend the data
\scriptsize
```{r echo=T, eval=T, message=F}
lm1 <- lm(values ~ lat + t + I(t^2), # fit a linear model
          data = Tmax_long) 
Tmax_long$residuals <- residuals(lm1) # store the residuals
```


Extract the spatial locations
```{r}
spat_df <- filter(Tmax_long, t == 1) %>% # lon/lat coords of stations
  select(lon, lat) %>% # select lon/lat only
  arrange(lon, lat) # sort ascending by lon/lat 
m <- length(unique(Tmax_long$id)) # number of stations
```

## Empirical Spatial Covariances and Plots

Put data in *space-wide* format
\scriptsize
```{r}
X <- Tmax_long %>% select(lon, lat, residuals, t) %>% # select columns
spread(t, residuals) %>% select(-lon, -lat) %>% t()
```



\normalsize
Calculate lag-0 and lag-1 covariance matrices (use `complete.obs`)

\scriptsize
```{r}
Lag0_cov <- cov(X, use = 'complete.obs')
Lag1_cov <- cov(X[-1, ], X[-nrow(X),],use = 'complete.obs')
```


## Empirical Spatial Covariances and Plots

\scriptsize
```{r}
# assign an index to each station
spat_df$n <- 1:nrow(spat_df) 

# range of lon coordinates
lim_lon <- range(spat_df$lon) 

# create 4 long. strip boundaries
lon_strips <- seq(lim_lon[1],lim_lon[2],length = 5)
spat_df$lon_strip <- cut(spat_df$lon, # bin the lon into
                         lon_strips, # their respective bins 
                         labels = FALSE, # don't assign labels
                         include.lowest = TRUE) # include edges
```


## Empirical Spatial Means Plot (By Year)

### Lag 0 covariances
\scriptsize
```{r echo=T, eval=T, message=F, fig.height=8, fig.width=8,fig.align='center'}
par(mfrow=c(2,2))
plot_cov_strips(Lag0_cov, spat_df) # plot the lag-0 matrices
```

## Empirical Spatial Means Plot (By Year)


### Lag 1 covariances

\scriptsize
```{r echo=T, eval=T, message=F, fig.height=8, fig.width=8,fig.align='center'}
par(mfrow=c(2,2))
plot_cov_strips(Lag1_cov, spat_df) # plot the lag-1 matrices
```

## Empirical Spatial Means Plot

### For areal data

\scriptsize
```{r echo=T, eval=T, message=F}
data("BEA", package = "STRbook") #income data
head(BEA %>% select(-Description), 3)
data("MOcounties", package = "STRbook")  #county geo data
```


## Empirical Spatial Means Plot

### For areal data

Join MO county boundary data with income

\scriptsize
```{r echo=T, eval=T, message=F,fig.height=3.2, fig.width=3.7, fig.align='center'}
MOcounties <- left_join(MOcounties, BEA, by = "NAME10")

County1 <- filter(MOcounties, NAME10 == "Clark, MO")
plot(County1$long, County1$lat, cex=0.7)
```


## Empirical Spatial Means Plot

### For areal data

\scriptsize
```{r echo=T, eval=F, message=F,fig.height=3.5, fig.width=4, fig.align='center'}
ggplot(MOcounties) +
  geom_polygon(aes(x = long, y = lat, # county boundary
                   group = NAME10, # county group 
                   fill = log(X1970))) + # log of income
  geom_path(aes(x = long, y = lat, # county boundary
                group = NAME10)) + # county group
  fill_scale(limits = c(7.5,10.2),name = "log($)") +
  coord_fixed() + ggtitle("1970") + # annotations
  xlab("x (m)") + ylab("y (m)") + theme_bw()
```


## Empirical Spatial Means Plot

### For areal data

\scriptsize
```{r echo=F, eval=T, message=F,fig.height=3.5, fig.width=4, fig.align='center'}
ggplot(MOcounties) +
  geom_polygon(aes(x = long, y = lat, # county boundary
                   group = NAME10, # county group 
                   fill = log(X1970))) + # log of income
  geom_path(aes(x = long, y = lat, # county boundary
                group = NAME10)) + # county group
  fill_scale(limits = c(7.5,10.2),name = "log($)") +
  coord_fixed() + ggtitle("1970") + # annotations
  xlab("x (m)") + ylab("y (m)") + theme_bw()
```


## Hovmoller Plot

\scriptsize
```{r}
lim_lat <- range(Tmax_long$lat)  # latitude range
lim_t <- range(Tmax_long$t) # time range
lat_axis <- seq(lim_lat[1], # latitude axis
                lim_lat[2],
                length=25) 
t_axis <- seq(lim_t[1], # time axis
              lim_t[2],
              length=100)
lat_t_grid <- expand.grid(lat = lat_axis,
                          t = t_axis)

```


```{r cache=T}
Tmax_grid <- Tmax_long
dists <- abs(outer(Tmax_long$lat, lat_axis, "-")) 
Tmax_grid$lat <- lat_axis[apply(dists, 1, which.min)]
```


```{r warning=F,message=F, cache=T}
 Tmax_lat_Hov <- Tmax_grid %>% group_by(lat, t) %>% 
  summarise(z = mean(values))
```


```{r}
ggplot(Tmax_lat_Hov) + # take data 
  geom_tile(aes(x = lat, y = t, fill = z)) + # plot
  fill_scale(name = "degF") + 
  scale_y_reverse() + 
  ylab("Day number (days)") + 
  xlab("Latitude (degrees)") + 
  theme_bw()
```


## On your own

\scriptsize

For the SST data loaded using the code below:

```{r}
data("SSTlandmask", package = "STRbook")
data("SSTlonlat", package = "STRbook")
data("SSTdata", package = "STRbook")
data("SST_df", package = "STRbook")
data("SST_EOFs", package = "STRbook")

table(SSTlandmask)  # 0: 2261    1: 259
dim(SSTlonlat)      # 2520    2
dim(SST_df)         # 1005480       8
names(SST_df)
str(E)  
dim(TS)
names(TS)
str(spat_mean)

#remove years that are not complete
rm_rows <- which(SSTlandmask == 1)
SSTdata <- SSTdata[-rm_rows, 1:396]
dim(SSTdata) # 2261  396
```

1. generate a data frame with the Empirical Spatial Means per decade (1970-1979, 1980-1989, 1990-2002) and plot them with one panel per decade


```{r warning=F,message=F}
summary(SST_df)
SST_df <- SST_df %>% filter(!is.na(Year),!is.na(sst))


SST_df$decade <- cut(SST_df$Year, # bin the year into
                         c(1970,1980,1990,2002), # their respective bins 
                         labels = c("70s","80s","90s-2002"), # don't assign labels
                         include.lowest = T) # include edges,right=F
summ <- SST_df %>% # mutate(decade=floor(Year/10)*10) %>%  year-year%%10 # floor_date(date,unit = 'year') # floor(decimal_date(date)/10)*10
                 group_by(decade) %>% 
  summarise(decade_means=mean(sst))
head(summ)
```

```{r}
SST_df %>% 
  group_by(lon,lat,decade) %>%
  summarise(z=mean(sst)) %>% 
  ggplot() + 
  geom_point(aes(x=lon,y=lat,colour=z),size=2) +
  col_scale(name = "mean_sst") + 
  xlab("Longitude (deg)") + 
  ylab("Latitude (deg)") + 
  geom_path(data = map_data("world"),# world boundaries
            aes(x = long, y = lat, group = group)) +
  coord_fixed(xlim = c(124, 290),
              ylim= c(-29,29)) +
  facet_wrap(.~decade,nrow=3)+
  theme_bw()
```


2. generate a spatial plot for the **yearly**  SST 95th quantile for the years 1980, 1990, 2000 having one panel per year

```{r}
SST_df %>% 
  filter(Year%in%c(1980,1990,2000)) %>% 
  group_by(lon,lat,Year) %>%
  summarise(z=quantile(sst,.95)) %>% 
  ggplot() + 
  geom_point(aes(x=lon,y=lat,colour=z),size=2) +
  col_scale(name = ".95q_sst") + 
  xlab("Longitude (deg)") + 
  ylab("Latitude (deg)") + 
  geom_path(data = map_data("world"),# world boundaries
            aes(x = long, y = lat, group = group)) +
  coord_fixed(xlim = c(124, 290),
              ylim= c(-29,29)) +
  facet_wrap(.~Year,nrow=3)+
  theme_bw()
```


3. Obtain a Hovmoller plot for these data

```{r}
lim_lat <- range(SST_df$lat)  # latitude range
lim_t <- range(SST_df$Year) # time range
lat_axis <- seq(lim_lat[1], # latitude axis
                lim_lat[2],
                length=59) 
t_axis <- seq(lim_t[1], # time axis
              lim_t[2],
              length=33)
lat_t_grid <- expand.grid(lat = lat_axis,
                          t = t_axis)
```


```{r}
SST_grid <- SST_df
dists <- abs(outer(SST_df$lat, lat_axis, "-")) 
SST_grid$lat <- lat_axis[apply(dists, 1, which.min)]
```

```{r}
SST_lat_Hov <- SST_grid %>% group_by(lat, Year) %>% 
summarise(z = mean(sst))
```

```{r}
ggplot(SST_lat_Hov) + # take data 
  geom_tile(aes(x = lat, y = Year, fill = z)) + # plot
  fill_scale(name = "mean_sst") + 
  scale_y_reverse() + 
  ylab("Years") + 
  xlab("Latitude (degrees)") + 
  theme_bw()
```

4. Calculate the EOFs for the *SST* dataset. Replicate the figures in pages 44-45 using the R function `eigen` (not `svd`) and `ggplot2::geom\_tile` and interpret them.  How many EOFs would you retain?


```{r}
## ------------------------------------------------------------------------
## Put data into space-wide form
Z <- t(SSTdata)
dim(Z)

## ------------------------------------------------------------------------
## First find the matrix we need to subtract:
spat_mean <- apply(SSTdata, 1, mean)
nT <- ncol(SSTdata)
nS <- nrow(SSTdata)
## Then subtract and standardize:
Zspat_detrend <- Z - outer(rep(1, nT), spat_mean)
Zt <- 1/sqrt(nT - 1)*Zspat_detrend
dim(Zt)
## ------------------------------------------------------------------------
E <- svd(Zt)
E$v[1:8,1:6]
E$u[392:396,392:396]
dim(E$v)
dim(E$u)
svd(Zt[1:5,1:5])

ATA <- eigen(t(Zt)%*%Zt,symmetric=T)
V <- ATA$vectors[,1:nT]*-1
V[1:8,1:6]
dim(V)
AAT <- eigen(Zt%*%t(Zt),symmetric=T)
U <- AAT$vectors
dim(U)
U[392:396,392:396]
D <- diag(sqrt(AAT$values))
dim(D)
z <- U%*%D%*%t(V)
z <- E$u%*%diag(E$d)%*%t(E$v)
z[1:5,1:5]

## ------------------------------------------------------------------------
# V <- E$v
# U <- E$u
colnames(V) <- paste0("EOF", 1:ncol(SSTdata)) # label columns
EOFs <- cbind(SSTlonlat[-rm_rows, ],V)
head(EOFs[,1:6])

## ------------------------------------------------------------------------
TS <- data.frame(U) %>%            # convert U to data frame
      mutate(t = 1:nrow(U)) %>%    # add a time field
      gather(EOF, PC, -t)            # put columns (except time)
                                     # into long-table format with
                                     # EOF-PC as key-value pair

## ------------------------------------------------------------------------
TS$nPC <- TS$PC * sqrt(nT-1)

## ------------------------------------------------------------------------
ggplot(EOFs) + geom_tile(aes(x = lon, y = lat, fill = EOF1)) +
   fill_scale(name = "degC") +
   xlab("Longitude (deg)") + ylab("Latitude (deg)")+
  geom_path(data = map_data("world"),# world boundaries
            aes(x = long, y = lat, group = group)) +
  coord_fixed(xlim = c(124, 290),
              ylim= c(-29,29)) + theme_bw()
```


<!-- ## EOF's -->

<!-- Calculate the EOFs for the *SST* dataset. Replicate the figures in pages 44-45 using the R functions \textsf{svd} and \textsf{ggplot2::geom\_tile} and interpret them.  How many EOFs would you retain? -->

<!-- ```{r echo=T, eval=F} -->
<!-- library(STRbook) -->
<!-- library(ggplot2) -->
<!-- library(tidyr) -->

<!-- data("SSTlandmask", package = "STRbook") -->
<!-- data("SSTlonlat", package = "STRbook") -->
<!-- data("SSTdata", package = "STRbook") -->

<!-- #remove years that are not complete -->
<!-- rm_rows <- which(SSTlandmask == 1) -->
<!-- SSTdata <- SSTdata[-rm_rows, 1:396] -->
<!-- ``` -->





<!-- ## Empirical Orthogonal Functions -->

<!-- To do dimension reduction, we need to decide the number of EOFs to use. How? -->

<!-- \bigskip -->
<!-- Here are some possibilities -->

<!--  -->
<!-- \benum -->
<!-- \item Use the $\lambda_k$'s to determine the proportion of overall variance to retain -->

<!--  -->
<!-- \bigskip -->
<!-- \item Use scree plot and find after including how many EOFs the variance contribution flattens out -->

<!--  -->
<!-- \bigskip -->
<!-- \item Identify the *significant* EOFs by obtaining EOFs for several spatially permuted versions of the data.  See where the tue scree plot intersects with those of the permuted datasets -->
<!-- \eenum -->


<!-- ## ST data classes in `spacetime` -->

<!-- \bdes -->
<!-- \item[Full grid] (**STF**) all possible space-time combinations  -->
<!-- \item[Sparse grid] (**STS**) contains only non-missing combinations on space-tiem lattice -->
<!-- \item[Irregular] (**STI**) irregular ST structure, each point has a coordinate and time stamp -->
<!-- \item[Simple trajectories] (**STT**) sequence of ST points that form trajectories -->
<!-- \edes -->


<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- Tmax_long2 <- filter(NOAA_df_1990, proc == "Tmax") -->
<!-- STObj <- stConstruct(x = Tmax_long2,           # data set -->
<!--                     space = c("lon", "lat"),  # spatial fields -->
<!--                     time = "date")            # time field -->
<!-- class(STObj) -->
<!-- ``` -->



<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- spat_part <- SpatialPoints(coords = Tmax_long2[, c("lon", "lat")]) -->
<!-- temp_part <- Tmax_long2$date -->
<!-- STObj2 <- STIDF(sp = spat_part, -->
<!--                 time = temp_part, -->
<!--                 data = select(Tmax_long2, -date, -lon, -lat)) -->
<!-- class(STObj2) -->
<!-- ``` -->


<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- spat_part <- SpatialPoints(coords = locs[, c("lon", "lat")]) -->
<!-- temp_part <- with(Times, -->
<!--                    paste(year, month, day, sep = "-")) -->
<!-- temp_part <- as.Date(temp_part) -->
<!-- ``` -->

<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- Tmax_long3 <- gather(Tmax, id, z, -julian, -year, -month, -day) -->
<!-- ``` -->


<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- Tmax_long3$id <- as.integer(Tmax_long3$id) -->
<!-- Tmax_long3 <- arrange(Tmax_long3,julian,id) -->
<!-- ``` -->

<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- all(unique(Tmax_long3$id) == locs$id) -->
<!-- ``` -->

<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- STObj3 <- STFDF(sp = spat_part, -->
<!--                 time = temp_part, -->
<!--                 data = Tmax_long3) -->
<!-- class(STObj3) -->
<!-- ``` -->

<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- proj4string(STObj3) <- CRS("+proj=longlat +ellps=WGS84") -->
<!-- ``` -->

<!-- ## ST data classes -->

<!-- \scriptsize -->
<!-- ```{r} -->
<!-- STObj3$z[STObj3$z == -9999] <- NA -->
<!-- ``` -->

<!-- ## Animations -->

<!-- \scriptsize -->
<!-- ```{r echo=F, eval=T, message=F, warning=F} -->
<!-- Tmax_long <- NOAA_df_1990 %>% # now subset the data -->
<!--   filter(proc == "Tmax" &     # only max temperature -->
<!--            month %in% 5:9 &   # May to September -->
<!--            year == 1993) %>%  # year 1993 -->
<!--   mutate(t=as.integer(julian-min(julian-1))) #create time variable -->



<!-- Tmax_t <- function(tau){ -->
<!--   Tmax_sub <- filter(Tmax_long, t == tau) # subset data  -->
<!--   ggplot(Tmax_sub) + -->
<!--     geom_point(aes(x = lon,y = lat, colour = values), size = 4) + -->
<!--     col_scale(name = "z", limits = c(40, 110)) +  -->
<!--     theme_bw() # B&W theme -->
<!-- } -->

<!-- lim_t <- range(Tmax_long$t) -->
<!-- gen_anim <- function(){ -->
<!--   for(t in lim_t[1]:lim_t[2]){ # for each time point -->
<!--     plot(Tmax_t(t)) #plot data at that time point -->
<!--   }  -->
<!-- } -->
<!-- ``` -->

<!-- ## Animations -->
<!-- \scriptsize -->
<!-- ```{r} -->
<!-- library(animation) -->
<!-- ani.options(interval = 0.2) # 0.2s interval between frames -->
<!-- saveHTML(gen_anim(),               # run the main function -->
<!--          autoplay = FALSE,         # do not play on load -->
<!--          loop = FALSE,             # do not loop -->
<!--          verbose = FALSE, -->
<!--          outdir = ".", -->
<!--          single.opts = "'controls': ['first', 'previous', 'play', 'next', 'last', 'loop', 'speed'], 'delayMin': 0", -->
<!--          htmlfile = "NOAA_anim.html") # save filename -->

<!-- ``` -->