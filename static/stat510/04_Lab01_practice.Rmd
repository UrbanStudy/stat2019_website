---
title: ''
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
header-includes:
 - \usepackage{fancyhdr}
 - \pagestyle{fancy}
 - \fancyhf{}
 - \rhead{Shen Qu}
 - \lhead{}
 - \chead{STAT 510}
 
---

```{r setup, echo=F, message=F, warning=FALSE}
knitr::opts_chunk$set(echo = T,collapse = T, message=F, warning=F, cache = T)
library(STRbook)
library(ggplot2)
library(dplyr)
library(tidyr)
library(tidyverse)
library(sp)
library(spacetime)
library(lubridate)
```



## Dacade Means

\scriptsize

For the SST data loaded using the code below:
Generate a data frame with the Empirical Spatial Means per decade (1970-1979, 1980-1989, 1990-2002) and plot them with one panel per decade

```{r,echo=F}
data("SSTlandmask", package = "STRbook")
data("SSTlonlat", package = "STRbook")
data("SSTdata", package = "STRbook")
data("SST_df", package = "STRbook")
data("SST_EOFs", package = "STRbook")

# table(SSTlandmask)  # 0: 2261    1: 259
# dim(SSTlonlat)      # 2520    2
# dim(SST_df)         # 1005480       8
# names(SST_df)
# str(E)  
# dim(TS)
# names(TS)
# str(spat_mean)

#remove years that are not complete
rm_rows <- which(SSTlandmask == 1)
SSTdata <- SSTdata[-rm_rows, 1:396]
# dim(SSTdata) # 2261  396
```


```{r warning=F,message=F}
# summary(SST_df)
SST_df <- SST_df %>% filter(!is.na(Year),!is.na(sst))
SST_df$decade <- cut(SST_df$Year, # bin the year into
                         c(1970,1980,1990,2002), # their respective bins 
                         labels = c("70s","80s","90s-2002"), # assign labels
                         include.lowest = T) # include edges,right=F
summ <- SST_df %>% group_by(decade) %>% summarise(decade_means=mean(sst))
# year-year%%10 # floor_date(date,unit = 'year') # floor(decimal_date(date)/10)*10
head(summ)
```

```{r, out.width='80%'}
SST_df %>% group_by(lon,lat,decade) %>% summarise(z=mean(sst)) %>% 
  ggplot() + 
  geom_point(aes(x=lon,y=lat,colour=z),size=1) +
  col_scale(name = "mean_sst") + 
  xlab("Longitude (deg)") + ylab("Latitude (deg)") + 
  geom_path(data = map_data("world"),# world boundaries
            aes(x = long, y = lat, group = group)) +
  coord_fixed(xlim = c(124, 290),ylim= c(-29,29)) +
  facet_wrap(.~decade,nrow=3)+
  theme_bw()
```

\pagebreak

## yearly 95th quantile

generate a spatial plot for the **yearly**  SST 95th quantile for the years 1980, 1990, 2000 having one panel per year

```{r}
SST_df %>% filter(Year%in%c(1980,1990,2000)) %>% 
  group_by(lon,lat,Year) %>% summarise(z=quantile(sst,.95)) %>% 
  ggplot() + 
  geom_point(aes(x=lon,y=lat,colour=z),size=1) +
  col_scale(name = ".95q_sst") + 
  xlab("Longitude (deg)") + ylab("Latitude (deg)") + 
  geom_path(data = map_data("world"),# world boundaries
            aes(x = long, y = lat, group = group)) +
  coord_fixed(xlim = c(124, 290),ylim= c(-29,29)) +
  facet_wrap(.~Year,nrow=3)+
  theme_bw()
```

\pagebreak

## Hovmoller plot

Obtain a Hovmoller plot for these data

```{r}
lim_lat <- range(SST_df$lat)  # latitude range
lim_t <- range(SST_df$Year) # time range
lat_axis <- seq(lim_lat[1], lim_lat[2],length=59) # latitude axis
t_axis <- seq(lim_t[1], lim_t[2],length=33)# time axis
lat_t_grid <- expand.grid(lat = lat_axis, t = t_axis)
```


```{r}
SST_grid <- SST_df
dists <- abs(outer(SST_df$lat, lat_axis, "-")) 
SST_grid$lat <- lat_axis[apply(dists, 1, which.min)]
```

```{r}
SST_lat_Hov <- SST_grid %>% group_by(lat, Year) %>% 
summarise(z = mean(sst))
```

```{r}
ggplot(SST_lat_Hov) +
  geom_tile(aes(x = lat, y = Year, fill = z)) + 
  fill_scale(name = "mean_sst") + scale_y_reverse() + 
  ylab("Years") + xlab("Latitude (degrees)") + 
  theme_bw()
```

\pagebreak

## EOFs

Calculate the EOFs for the *SST* dataset. Replicate the figures in pages 44-45 using the R function `eigen` (not `svd`) and `ggplot2::geom\_tile` and interpret them.  How many EOFs would you retain?


```{r}
Z <- t(SSTdata) # dim(Z)
spat_mean <- apply(SSTdata, 1, mean)
nT <- ncol(SSTdata)
nS <- nrow(SSTdata)
Zspat_detrend <- Z - outer(rep(1, nT), spat_mean) #subtract and standardize:
Zt <- 1/sqrt(nT - 1)*Zspat_detrend # dim(Zt)
```


```{r eval=T,echo=F}
E <- svd(Zt)
# E$v[1:8,1:6]
# E$u[392:396,392:396]
# dim(E$v)
# dim(E$u)
# svd(Zt[1:5,1:5])
# V <- E$v
# U <- E$u
```


```{r}
ATA <- eigen(t(Zt)%*%Zt,symmetric=T)
V <- ATA$vectors[,1:nT]
AAT <- eigen(Zt%*%t(Zt),symmetric=T)
U <- AAT$vectors
D <- diag(sqrt(AAT$values))
```

```{r}
round(E$v[1:5,1:8],4)
round(V[1:5,1:8],4)
```


```{r}
V[,c(1,2,4)] <- V[,c(1,2,4)]*-1
```

\normalsize

> Use 'eigen' function, the columns 1, 2, 4 in "V" matrix have inverse sign to these in "V" by "svd" function

```{r, eval=F,echo=F}
dim(V)
dim(U)
U[392:396,392:396]
dim(D)
z <- U%*%D%*%t(V)
z <- E$u%*%diag(E$d)%*%t(E$v)
z[1:5,1:5]
```


```{r}
colnames(V) <- paste0("EOF", 1:ncol(SSTdata)) # label columns
EOFs <- cbind(SSTlonlat[-rm_rows, ],V) # head(EOFs[,1:6])
```

```{r}
E100 <- matrix(rep(NA,100*nT),100,nT) %>% as.data.frame()
for (i in 1:100) {
s.id <- sample(1:nS,nS,replace = F)
E100[i,] <- svd(Zt[,s.id])$d
}
colnames(E100) <-1:nT  #paste0("rank", 1:nT) 
E100.long <- E100[,1:50] %>%  
      gather(rank,EOF,factor_key=T) 
E100.long$EOF <- E100.long$EOF/sum(E$d)
```


```{r,echo=F,out.width='48%'}
ggplot()+geom_point(aes(x=as.factor(1:50),y=((AAT$values)[1:50])/sum(AAT$values)))+
geom_boxplot(aes(x=rank,y=EOF),data=E100.long,col="red") +theme_bw()# ,show.legend = NA

ggplot()+geom_point(aes(x=as.factor(5:20),y=((AAT$values)[5:20])/sum(AAT$values)))+
         geom_boxplot(aes(x=rank,y=EOF),data=subset(E100.long,rank%in%5:20),col="red") + #ylim(0,.1)+
         theme_bw()
```


The black points in the scree plot correspond to the relative variance associated with the first 50 EOFs for the
SST data.
The red boxplots of relative variances obtained from EOF analyses of 100 random permutations of the data. 

The zoom-in plot shows the two curves intersect between 11 and 12, suggesting that there is very little "real" variability being accounted for by the EOFs with indices greater than about 12.


```{r}
EOFs.long <- EOFs[,1:14] %>%  
      gather(EOF_id,EOF ,-lon,-lat,factor_key=T) # levels(EOFs.long$EOF_id) <- 1:12
ggplot(EOFs.long) + geom_tile(aes(x = lon, y = lat, fill =EOF)) + # 
   fill_scale(name = "degC") +
   xlab("Longitude (deg)") + ylab("Latitude (deg)")+
  geom_path(data = map_data("world"),# world boundaries
            aes(x = long, y = lat, group = group)) +
  coord_fixed(xlim = c(124, 290),ylim= c(-29,29)) + 
  facet_wrap(vars(EOF_id),ncol = 3) + # ,labeller = "label_value"
  theme_bw()
```

https://stats.idre.ucla.edu/r/codefragments/svd_demos/

\pagebreak

## inclass problems 1

- Semivariogram

Let \(Z_1, Z_2\) represent \(Z(s+h;t+\tau)\) and \(Z(s;t)\), \(\mu_1, \mu_2\) represent \(\mu(s+h;t+\tau)\) and \(Z(s;t)\), 

\[\begin{aligned}
C_{z}(h;\tau)&={E}[(Z(s;t)-{\mu}(s;t))(Z(s+h;t+\tau)-{\mu}(s+h;t+\tau)]\\
&=E[(Z_1-\mu_1)(Z_2-\mu_2)]\\
&=\text{Cov}[Z_1,Z_2]
\end{aligned}\]


\[\begin{aligned}
C_{z}(0;0)&={E}[(Z(s+h;t+\tau)-{\mu}(s+h;t+\tau)^2]=\text{Var}[Z_1]\\
C_{z}(0;0)&={E}[(Z(s;t)-{\mu}(s;t))^2]=\text{Var}[Z_2]\\
\end{aligned}\]


\[\begin{aligned}
\text{Var}[Z_1-Z_2]&=\text{Var}[Z_1]+\text{Var}[Z_2]-2\text{Cov}[Z_1,Z_2]\\
&=C_z(0,0)+C_z(0,0)-2C_z(h,\tau)\\
\end{aligned}\]

Therefore,

\[\frac12\text{Var}[Z(s+h;t+\tau)-Z(s;t)]=C_z(0,0)-C_z(h,\tau).\]

- Canonical correlation

\[\begin{aligned}
a_k(t_j)&=\sum_{i=1}^m \xi_{ik} Z(s_i;t_j)\;=\;\boldsymbol{\xi}_k' \mathbf{Z}_{t_j}\\
b_k(t_j)&=\sum_{\ell=1}^n \psi_{\ell k} X(r_{\ell};t_j)\;=\;\boldsymbol{\psi}_k' \mathbf{X}_{t_j}\\
\end{aligned}\]

\[\begin{aligned}
Var[a_k(t_j)]&=\boldsymbol{\xi}_k' \mathbf{Z}_{t_j}(\boldsymbol{\xi}_k' \mathbf{Z}_{t_j})'=\boldsymbol{\xi}_k' \mathbf{Z}_{t_j}\mathbf{Z}'_{t_j}\boldsymbol{\xi}_k=\boldsymbol{\xi}'_k{C}_z^{(0)}\boldsymbol{\xi}_k \quad(C_z \text{ is symmetric})\\
Var[b_k(t_j)]&=\boldsymbol{\psi}_k' \mathbf{X}_{t_j}(\boldsymbol{\psi}_k' \mathbf{X}_{t_j})'=\boldsymbol{\psi}_k' \mathbf{X}_{t_j}\mathbf{X}'_{t_j}\boldsymbol{\psi}_k=\boldsymbol{\psi}'_k{C}_x^{(0)}\boldsymbol{\psi}_k \quad(C_x \text{ is symmetric})\\
Cov[a_k(t_j),b_k(t_j)]&=\boldsymbol{\xi}_k' \mathbf{Z}_{t_j}(\boldsymbol{\psi}_k' \mathbf{X}_{t_j})'=\boldsymbol{\xi}_k' \mathbf{Z}_{t_j}\mathbf{X}'_{t_j}\boldsymbol{\psi}_k=\boldsymbol{\xi}'_k{C}_{z,x}^{(0)}\boldsymbol{\psi}_k\\
\end{aligned}\]


\[r_k=\text{corr}(a_k,b_k)=\frac{Cov[a_k(t_j),b_k(t_j)]}{\sqrt{Var[a_k(t_j),Var[b_k(t_j)]]}}=\frac{\boldsymbol{\xi}_k' \mathbf{C}_{z,x}^{(0)} \boldsymbol{\psi}_k}{(\boldsymbol{\xi}_k' \mathbf{C}_{z}^{(0)} \boldsymbol{\xi}_k)^{1/2} (\boldsymbol{\psi}_k' \mathbf{C}_{x}^{(0)} \boldsymbol{\psi}_k)^{1/2}}\]


\pagebreak

## inclass problems 2

```{r, echo=F}
library("dplyr")
library("fields")
library("ggplot2")
library("gstat")
library("RColorBrewer")
library("sp")
library("spacetime")
library("STRbook")
```

```{r}
data("NOAA_df_1990", package = "STRbook")
Tmin <- filter(NOAA_df_1990,       # subset the data
              proc == "Tmin" &     # only min temperature
              month %in% 7 &       # only July
              year == 1993 &      # year of 1993
              day != 14) %>%      # remove day 14
              mutate(t=as.integer(julian-min(julian-1))) #create time variable
pred_grid <- expand.grid(lon = seq(-100, -80, length = 20),
                         lat = seq(32, 46, length = 20),
                         day = c(4, 14, 29))
```


```{r}
Tmin_July_idw <- idw(formula = z ~ 1,            # dep. variable
                     locations = ~ lon + lat + day, # inputs
                     data = Tmin,                # data set
                     newdata = pred_grid,        # prediction grid
                     idp = 5)                    # inv. dist. pow.
```


```{r}
pred_obs_dist_mat <- rdist(select(pred_grid, lon, lat, day),
                           select(Tmin, lon, lat, day))
Wt_IDW <- function(theta, dist_mat) 1/dist_mat^theta
Wtilde <- Wt_IDW(theta = 5, dist_mat = pred_obs_dist_mat)
Wtilde_rsums <- rowSums(Wtilde)
W <- Wtilde/Wtilde_rsums # Weights
z_pred_IDW <- as.numeric(W %*% Tmin$z)
pred_grid$z.hat <- as.numeric(W %*% Tmin$z)
```

```{r}
ggplot(pred_grid) +
    geom_tile(aes(x = lon, y = lat,fill = z.hat)) +
    fill_scale(name = "degF") +                         # attach color scale
    xlab("Longitude (deg)") + ylab("Latitude (deg)") +  # x,y-axis label
    facet_wrap(~ day, ncol = 3) +                       # facet by day
    coord_fixed(xlim = c(-100, -80),ylim = c(32, 46))  + theme_bw() 
```

```{r}
summary(Tmin_July_idw$var1.pred - z_pred_IDW)
```

The results of computed predictions between 'idw' function and using 'rdist' are very close.


\pagebreak

## inclass problems 3

Using the dataset 

```{r}
Tmax_long <- NOAA_df_1990 %>% # now subset the data
filter(proc == "Tmax" & # only max temperature
month %in% 7 & # only July
year == 1993) %>%
mutate(t=as.integer(julian-min(julian-1))) #create time variable
```

together with the functions defined below,cross-validate predictions 

```{r}
library(fields)
# "data" must include variables: lon, lat, t and z
K.fold.cv <- function(data,nfolds=5,weight.fn,theta){
mT <- nrow(data)
Z <- data$z
coords <- data %>% dplyr::select(lon,lat,t)
dist_mat <- rdist(coords,coords)
# sample fold label vector
if(nfolds < mT){fold.vec <- sample(1:nfolds,mT,replace = T)
          }else{fold.vec <- 1:mT}
w.tilde <- weight.fn(theta,dist_mat)
MSPEk <- 1:nfolds %>% 
         map_dbl(function(x){
                 hold.out <- which(fold.vec==x)
                        w <- w.tilde[hold.out,-hold.out,drop=F]
                        w <- w * (1/rowSums(w))
                    Z.hat <- w %*% Z[-hold.out]
                    mean((Z[hold.out]-Z.hat)^2)
                }) # CV score
return(mean(MSPEk))
}
```

with a Gaussian kernel 

```{r}
weight.gauss <- function(theta, dist_mat){
                         exp(-dist_mat^2/theta)
}
```

setting the number of folds to $K = 5, 10, m_T$(leave-one-outCV), and the values of $\theta = 0.2, 0.4, . . . , 2$.


```{r}
theta <- seq(0.2,2,0.2)
folds <- c(5,10,nrow(Tmax_long))
cv <- data.frame(folds=rep(folds,each=length(theta)),
           theta=rep(theta,times=length(folds)),
           score=NA)
for (i in 1:3) { # 
  for (j in 1:10) { # 
      cv[(i-1)*10+j,3] <- K.fold.cv(data=Tmax_long,
      nfolds=folds[i],
      weight.fn = weight.gauss,
      theta=theta[j])
  }
}
```


Compare the 5, 10 and LOO cv procedures by contrasting their corresponding CV-scores vs $\theta$ curves.

```{r, echo=F,out.width='50%'}
ggplot(cv,aes(x =theta, y = score,group = folds,col=as.factor(folds))) +
    geom_line() + geom_point(size = 2) +  
    theme_bw()  + labs(x=expression(theta),y="CV-score")
```

```{r}
cv.map <- data.frame(folds=rep(folds,each=length(theta)),
           theta=rep(theta,times=length(folds)),
           score=NA)
for (i in 1:3) { 
cv.map[10*(i-1)+1:10,3] <-  map_dbl(theta,~K.fold.cv(data=Tmax_long,
      nfolds=folds[i],
      weight.fn = weight.gauss,
      theta=.x))
}

cv.map[,3] <- map2_dbl(folds,theta, ~ K.fold.cv(data=Tmax_long, nfolds=.x, weight.fn=weight.gauss, theta=.y))
```

Error: Mapped vectors must have consistent lengths:

```{r, eval=T, echo=F}
ggplot(cv.map,aes(x =theta, y = score,group = folds,col=as.factor(folds))) +
    geom_line() +
    geom_point(size = 2) +    # point
    theme_bw()  +             # B&W theme
   labs(x=expression(theta),y="CV-score")
```

