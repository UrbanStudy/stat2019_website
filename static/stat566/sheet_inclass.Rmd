---
title: ''
fontfamily: mathpazo
fontsize: 10pt
geometry: margin=3mm
linestretch: 0.1
classoption:
- twocolumn
pagenumbering: FALSE
whitespace: none
output:
  pdf_document:
    toc: FALSE
    number_sections: FALSE
header-includes:
    - \usepackage{booktabs}
    - \usepackage{tabularx}
    - \usepackage[fleqn]{mathtools}
    - \setlength\tabcolsep{0.0pt}
    - \setlength\lineskip{0pt}
    - \setlength\parskip{0pt}


    
---

\fontsize{6pt}{0pt}

\footnotesize

small,scriptsize,tiny,p0.5linewidth

##### Simple linear

$S_{xx}\sum_{i=1}^{10}(x_i-\bar x)^2=472$,$S_{yy}=\sum_{i=1}^{10}(y_i-\bar y)^2=731$, $S_{xy}\sum_{i=1}^{10}(x_i-\bar x)(y_i-\bar y)=274$

$\hat\beta_1=\frac{S_{xy}}{S_{xx}}=\frac{274}{472}=0.5805$;
$\hat\beta_0=\bar y-\hat\beta_1\bar x=\bar y-0.5805\bar x$

$\hat\sigma^2=\frac{SSE}{n-2}=\frac18(S_{yy}-\frac{S^2_{xy}}{S_{xx}})=\frac18(731-\frac{274^2}{472})=71.4926$

$\hat\beta_1\sim N(\beta_1,\frac{\hat\sigma^2}{S_{xx}})$;$\hat\beta_0\sim N(\beta_0,\hat\sigma^2[\frac1n+\frac{\bar x^2}{S_{xx}}])$;

$Var(\hat\beta_1)=\frac{71.4926}{472}=0.1515$;
$Var(\hat\beta_1)=71.4926(\frac1{10}+\frac{\bar x^2}{472})$

$H_0: \hat\beta_1=0$;
$t_0=\frac{\hat\beta_1-0}{\sqrt{Var(\hat\beta_1)}}=\frac{0.5805085}{\sqrt{0.1514673}}=1.491589<t_{\frac{0.05}{2},n-2}=2.31$Fail to reject 

$\hat\beta_1\pm t_{\frac{0.05}{k+1},n-2}se(\hat\beta_1)=0.5805085\pm2.31\sqrt{0.1514673}$, $(-0.3185158,1.479533)$

$\hat y=\hat\beta_0+\hat\beta_1x_0=168.3609$;$\bar x=147.6923$,$S_{XX}=\sum_{i=1}^{13}(x_i-\bar x)^2=6230.769$

Confidence interval:
$se(y_0)=\sqrt{MSE(\frac1n+\frac{(x_0-\bar x)^2}{S_{XX}})}=\sqrt{275.06005(\frac1{13}+\frac{(170-147.6923)^2}{6230.769})}=6.567093$

$\hat y\pm t_{n-2,0.025}se(y_0)=168.3609\pm2.200985*6.567093$, $(153.9068,182.815)$

Prediction interval:
$se(y_0)=\sqrt{MSE(1+\frac1n+\frac{(x_0-\bar x)^2}{S_{XX}})}=17.83779$;
$168.3609\pm2.200985*17.83779$; $(129.1002,207.6216)$



##### Multi linear

- least-squares estimators

$SSE=\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i-\beta_2x_i^2)^2$

$\frac{\partial SSE}{\partial\beta_{0,1,2}}=2\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i-\beta_2x_i^2)(-1,-x_i,-x_i^2)\overset{set}{=}0$

- Regression with indicator

$y_i=\beta_0+\beta_1x_i+\beta_2w_i+\beta_3w_ix_i+\varepsilon_i$, $w_i=\begin{cases}0& 1\le i\le\frac{n}2\\1& \frac{n}2+1\le i\le n\end{cases}$

$\mathbf{Y_{n\times1}}=\mathbf{X_{n\times (k+1)}}\mathbf{\beta_{(k+1)\times1}}+\mathbf{\varepsilon_{n\times1}}$

equality of slopes $H_0:\beta_3=0$, $k=3$,$r=1$ 

$dfE_{Ful}=n-(k+1)$,$dfE_{Red}-dfE_{Ful}=r$

- Partitioned regression

\begin{tabular}{ l|l|l|l|l|l }
(df)&$SS_{F}$              &$-SS_{3,4,5}$ &$SS_{1,2}$ &$-SS_{2,4}$ &$SS_{1,3,5}$\\
R   &$\sum\limits_{i=1}^5=367(5)$ & $-\sum\limits_{i=3}^5$ & $\sum\limits_{i=1}^2=271(2)$ &-153(2) &214(3)\\
E   &T-R=336(69)           &   +96(3)        & 432(72)               &+153(2) &489(71)\\
T   &  703(74)
\end{tabular}

$H_0: \beta_3=\beta_4=\beta_5=0$; $r=3$; $H_0':\beta_2=\beta_4=0$; $r=2$;

$F_{p,3,69}=\frac{96/3}{336/69}=6.5714$;$F'=\frac{153/2}{336/69}=15.7098$
$p<0.05$ reject $H_0$ at 0.05 level of significance

$R^2=\frac{SSR}{SST}=\frac{271}{703}=0.3855$ coefficient of determination is the proportion of variation explained by the regressor x

$R^2_{adj}=1-\frac{SSE/dfE}{SST/dfT}=1-\frac{432/72}{703/74}=0.3684$

CI: $\hat\beta_1\pm t_{\frac{\alpha}{2},n-k-1}se(\hat\beta_1)$, $se(\hat\beta_1)=\sqrt{MSE\cdot C_{22}}$;
$8.1556\pm t(0.005,9)\sqrt{8.84355*0.2483463917}$, $8.1556\pm3.25\times4.407127$;$(-6.1653,22.4765)$

unbiased estimate of the variance 
$Var(\hat\beta_1-\hat\beta_2)=Var(\hat\beta_1)+Var(\hat\beta_2)-Cov(\hat\beta_1,\hat\beta_2)=0.2483+10.7694-2(-0.4967)=12.0111$

- Lack of fit $H_0$: There is no lack of fit, the model is appropriate;

$SS_{PE}=\sum_{i=1}^m\sum_{j=1}^{n_i}(y_{ij}-\bar y_i)^2=28$; 
$df_{PE}=n-m=12-9=3$; 
$MS_{PE}=28/3$

$SSE=SS_{LOF}+SS_{PE}$,
$\sum_{i=1}^m\sum_{j=1}^{n_i}(y_{ij}-\hat y_i)^2=\sum_{i=1}^m\sum_{j=1}^{n_i}(y_{ij}-\bar y_i)^2+\sum_{i=1}^mn_i(y_{ij}-\hat y_i)^2$

$SS_{LOF}=SSE-SS_{PE}=703.87576-28=675.8758$; 
$df_{LOF}=dfE-df_{PE}=m-2=7$

$F=\frac{SS_{LOF}/df_{LOF}}{MS_{PE}}=\frac{675.87576/7}{28/3}=10.34504>F(0.05,6,3)=8.94$. Reject

##### CRD

$y_{ijkl}=\mu+\tau_i+\beta_j+(\tau\beta)_{ij}+\varepsilon_{ijk}$, 
$i=1,2$; $j=1,2,3$; $k=1,2,3,4$; $l=1,2,[a=2,b=3,n=4]$ where $\mu$ overall mean

$\tau_i$ is fixed main effect of $i^{th}$ level of  Factor A;

$\beta_j$ is fixed main effect of $j^{th}$ level of Factor B;

$(\tau\beta)_{ij}$ is fixed interaction effect of $i^{th}$ level of Factor A and $j^{th}$ level of Factor B;

$\varepsilon_{ijkl}$ is random error for the $k^{th}$ replicate EU when $i^{th}$ level of Factor A and $j^{th}$ level of Factor B are applied;
$y_{ijkl}$ is response for the;

Assumptions: $\varepsilon_{ijk}\sim iid N(0,\sigma^2)$ (constant variance, zero mean, independent); $\sum_i^2\tau_i=0$; $\sum_j^3\beta_j=0$; $\sum_i^2(\tau\beta)_{ij}=0$; $\sum_j^3(\tau\beta)_{ij}=0$

\begin{tabular}{l|l|l|l|l|l|l}
term &i(f) &j(f) &k(r) & df & SS & EMS\\\hline
A$\tau_{i}$f &0&b&n&a-1&$bn\sum^a(\bar y_{i..}-\bar y_{...})^2$;$\frac{\sum^ay_{i..}^2}{bn}-\frac{y_{...}^2}{abn}$;96;96&$\sigma^2+\frac{b\sum\tau_i^2}{a-1}$\\\hline

B$\beta_{ij}$f &a&0&n&b-1&$an\sum^b(\bar y_{.j.}-\bar y_{...})^2$;$\frac{\sum^by_{.j.}^2}{an}-\frac{y_{...}^2}{abn}$;208;104&$\sigma^2+\frac{a\sum\beta_j^2}{b-1}$\\\hline

\shortstack{AB\\$(\tau\beta)_{ij}$f} &0&0&n&(a-1)(b-1)&\shortstack{$n\sum^a\sum^b(y_{ij.}-\bar y_{i..}-\bar y_{.j.}+\bar y_{...})^2$;112;56\\$n\sum\sum y_{ij.}^2-\frac{1}{abn}y_{...}^2-SS_A-SS_B$}&$\sigma^2+\frac{\sum\sum(\tau\beta)_{ij}}{(a-1)(b-1)}$\\\hline

E$\varepsilon_{ijk}$r&1&1&1&ab(n-1)&$SST-\sum SS$;$(n-1)\sum^a\sum^bS_{ij}^2$;126;7&$\sigma^2$\\\hline

Total& & & &abn-1&$\sum\sum\sum(y_{ijk}-\bar y_{...})^2$$\sum\sum\sum y_{ijk}^2-\frac{y_{...}^2}{abn};542$
\end{tabular}

$H_0:(\tau\beta)_{ij}=0\forall i,j$; $F_{p,2,18}\frac{MS_{AB}}{MSE}=\frac{56}7=8$; $F_{0.05,2,8}=3.55$. There is enough evidence to reject $H_0$. The model may not be reduced, as the interaction effects is significant at 5% significance level.

$\bar y_{12.}-\bar y_{22.}\pm t_{\frac\alpha2,18}\sqrt{\frac{2MSE}n}=14-8\pm2.1\sqrt{\frac{2*7}4}=6\pm3.9287$;$[2.0713,9.9287]$


##### Latin Square

$y_{ijk}=\mu+\tau_i+\alpha_j+\beta_k+\varepsilon_{ijk}$, $i,j,k=1,..,6$; where $\mu$ overall mean

$\tau_i$ is effect of $i^{th}$ treatment; 
$\alpha_j$ is effect of $j^{th}$ block of factor R; 
$\beta_k$ effect of $k^{th}$ block of factor C;

$\varepsilon_{ijkl}$ is random error when $i^{th}$ treatment is applied at $j^{th}$ block of factor R and $k^{th}$ block of factor C; $y_{ijkl}$ is response ;

Assumptions: $\varepsilon_{ijk}\sim iid N(0,\sigma^2)$. Further assumptions would be based on whether the treatment and blocking factors are random or fixed.

The Latin-Squre design can only use 2 blocking factors, as we distribute the levels of the treatment factor on a table with rows of one blocking factor (each row is fore one block) and columns of the other blocking factor (each column is one block)

You can test three blocking factors by turning the Latin-square design into a Graeco-Latin square design, which allows to add a Greek letter to each entry in the table, where each Greek letter stands for a block of the factor G.

Relative Efficiency 
$\frac{(df_{E(LS)}+1)(df_{E(CRD)}+3)}{(df_{E(LS)}+3)(df_{E(CRD)}+1)}=2.3$

$df_{E(LS)}=(p-1)(p-2)=20$,$(df_{E(GS)}=(p-1)(p-3)=15$, $df_{E(CRD)}=a(n-1)$

##### BIBD

Trt$a=7$,Rep$r=15$, Blk$b=21$,Size$k=5$, $ar=bk=105$, replications of each pair$\lambda=\frac{(k-1)}{a-1}r=\frac{k(k-1)}{a(a-1)}b=10$

$\lambda=\frac{2}{3}r\in\mathbf{N^+}$the smallest number of observations per treatment is a multiple of 3 and 5



##### Factorial model

$k$ factors,$p$ generators; $2^p$ blocks/fraction;$2^{k-p}$Run, Blk size;

$2^p-1$ alias; $2^p-p-1$ auto confounded;

I=ABC=BCD=AD

AD+,ABC-,BCD-;(1),bc,abd,acd;ABC+BCD+;b,c,ad,abcd

AD-,ABC-,BCD+;ab,ac,bcd,d;ABC+BCD-;a,abc,bd,cd


ANOVA-df: T$=2^kn-1$;Blk$=2^p-1$;E$=2^k(n-1)$;others=1


\begin{tabular}{ l|l|l|l|l|l }
$2^{k-p}$      &$2^k$&$2^{p}$&$2^{k-p}$&Generator\\
$2^{3-1}_{III}$&8  &2 &4 &  C=AB\\
$2^{4-1}_{IV}$ &16 &2 &8 &  D=ABC\\
$2^{5-1}_{V}$  &32 &2 &16&  E=ABCD\\
$2^{5-2}_{III}$&32 &4 & 8&  D=AB;E=AC\\
$2^{6-1}_{VI}$ &64 &2 &32&  F=ABCDE\\
$2^{6-2}_{IV}$ &64 &4 &16&  E=ABC;F=BCD & A-F;AB;AC;AD;(AE);AF;BD;BF;(ABD);(ACD)\\
$2^{6-3}_{III}$&64 &8 &8 &  D=AB;E=AC;F=BC\\
$2^{7-1}_{VII}$&128&2 &64&  G=ABCDEF\\
$2^{7-2}_{IV}$ &128&4 &32&  F=ABCD;G=ABDE & I=ABCDF=ABDEG=CEFG;CE=FG,CF=EG,CG=EF minimum aberration\\
$2^{7-3}_{IV}$ &128&8 &16&  E=ABC;F=BCD;G=ACD & $2^p-p-1=4$ generalized interactions\\
$2^{7-4}_{III}$&128&16&8 &  D=AB;E=AC;F=BC;G=ABC
\end{tabular}


##### Fixed v.s. random; crossed v.s. nested

(a)Fixed effects are constant across individuals, random effects vary. 
Effects are fixed if they are interesting in themselves or random if there is interest in the underlying population.
When a sample exhausts the population, the corresponding variable is fixed; when the sample is a small part of the population the corresponding variable is random.
If an effect is assumed to be a realized value of a random variable, it is called a random effect.
Fixed effects are estimated using least squares and random effects are estimated with shrinkage.

**Example**: A lab want to test the quality of products. There are only two test machines. Each machine assigned two operators who randomly sellected from a large amont of operators. Each poerator test the products in three specific temperature. In this test, the factor mathine and temperature have fixed effects. The factor operator has random effects.

(b)Two factors are crossed when every category of one factor co-occurs in the design with every category of the other factor. There is at least one observation in every combination of categories for the two factors.

A factor is nested within another factor when each category of the first factor co-occurs with only one category of the other. An observation has to be within one category of Factor 2 in order to have a specific category of Factor 1. All combinations of categories are not represented.

You can calculate an interaction between two crossed factors. If they are nested, you cannot because you do not have every combination of one factor along with every combination of the other.

In **Example** (a), Three temperature are applied on each machine. Thus, temperature and machine have crossed effect. The operators were assigned to each machine are different. The operators are nested in the levels of factor machine. Thus, the effects of the factor operator are nested effect.

##### Mixed model

$y_{ijk}=\mu+\alpha_i+\beta_{ij}+\varepsilon_{ijk}$; $\sum_{i=1}^a\alpha_i=0$, $\beta_{ij}\sim N(0,\sigma_{\beta}^2)$, $\varepsilon_{ij}\sim N(0,\sigma_{\varepsilon}^2)$

$Cov(y_{111},y_{112})=Cov(\beta_{11}+\varepsilon_{111},\beta_{11}+\varepsilon_{112})=Var(\beta_{11})+Cov(\varepsilon_{111},\varepsilon_{112})=\sigma^2_{\beta}$

$Cov(y_{111},y_{121})=Cov(\beta_{11}+\varepsilon_{111},\beta_{12}+\varepsilon_{121})=Cov(\beta_{11},\beta_{12})+Cov(\varepsilon_{111},\varepsilon_{121})=0$

$Cov(y_{111},y_{211})=Cov(\beta_{11}+\varepsilon_{111},\beta_{21}+\varepsilon_{211})=Cov(\beta_{11},\beta_{21})+Cov(\varepsilon_{111},\varepsilon_{211})=0$

$Var(y_{111})=\sigma^2_{\beta}+\sigma_{\varepsilon}^2=Var(y_{112})$; $Cor(y_{111},y_{112})=\frac{\sigma^2_{\beta}}{\sigma^2_{\beta}+\sigma_{\varepsilon}^2}$
$Cor(y_{111},y_{121})=Cor(y_{111},y_{211})=0$

A linear combination of normal distributed random variables and constants are normal distributed.

$E[\bar y_{ij.}]=E[\frac1n\sum_{k=1}^ny_{ijk}]=\frac{\sum_{k=1}^n}nE[\mu+\alpha_i+\beta_{ij}+\varepsilon_{ijk}]=\mu+\alpha_i,\forall i=1,..,a;j=1,..,b$

$Var[\bar y_{ij.}]=Var[\frac1n\sum_{k=1}^ny_{ijk}]=\frac{\sum_{k=1}^n}{n^2}Var[\mu+\alpha_i+\beta_{ij}+\varepsilon_{ijk}]=\frac1n(\sigma^2_{\beta}+\sigma_{\varepsilon}^2),\forall i=1,..,a;j=1,..,b$

$f(\bar y_{i1.},..\bar y_{ib.})=\prod_{j=1}^bf(\bar y_{ij.})=(2\pi\frac{\sigma^2_{\beta}+\sigma_{\varepsilon}^2}n)^{-\frac{b}2}\exp[\frac{-n}{2(\sigma^2_{\beta}+\sigma_{\varepsilon}^2)}\sum_{j=1}^b(\bar y_{ij.}-\mu-\alpha_i)^2]$

$\hat\alpha_1-\hat\alpha_2\sim N(\alpha_1-\alpha_2,\frac2{b}\sigma^2_{\beta}+\frac2{bn}\sigma_{\varepsilon}^2)$

$\frac{\partial SSE}{\partial\alpha_i}=2\sum_{j=1}^b\sum_{k=1}^n(y_{ijk}-\mu-\alpha_i-\beta_{ij})(-1)\overset{set}{=}0$;
$\hat\alpha_i=\frac1{bn}\sum_{j=1}^b\sum_{k=1}^ny_{ijk}-\mu-\frac1{b}\sum_{j=1}^b\beta_{ij}=\bar y_{i..}-\mu$

$\hat\alpha_1-\hat\alpha_2=\bar y_{1..}-\mu-(\bar y_{2..}-\mu)=\frac{\sum_{j=1}^b\sum_{k=1}^n(y_{1jk}-y_{2jk})}{bn}=\frac{\sum_{j=1}^b\sum_{k=1}^n(\alpha_1-\alpha_2+\beta_{1j}-\beta_{2j}+\varepsilon_{1jk}-\varepsilon_{2jk})}{bn}=\alpha_1-\alpha_2+\bar\beta_{1.}-\bar\beta_{2.}+\bar\varepsilon_{1..}-\bar\varepsilon_{2..}$

$Var[\hat\alpha_1-\hat\alpha_2]=Var[\bar\beta_{1.}-\bar\beta_{2.}+\bar\varepsilon_{1..}-\bar\varepsilon_{2..}]=\frac{\sum_{j=1}^{b}}{b^2}(Var[\beta_{1.}]+Var[\beta_{2.}])+\frac{\sum_{j=1}^b\sum_{k=1}^n}{b^2n^2}(Var[\varepsilon_{1..}]+Var[\varepsilon_{2..}])=\frac2{b}\sigma^2_{\beta}+\frac2{bn}\sigma_{\varepsilon}^2$

$E[\hat\alpha_1-\hat\alpha_2]=\alpha_1-\alpha_2$; 
$SSE=\sum_{i=1}^a\sum_{j=1}^b\sum_{k=1}^n(y_{ijk}-\mu-\alpha_i-\beta_{ij})^2$

$\bar y_{ij.}-\bar y_{i..}=\mu+\alpha_i+\beta_{ij}+\bar\varepsilon_{ij.}-(\mu+\alpha_i+\bar\beta_{i.}+\bar\varepsilon_{i..})=\beta_{ij}-\bar\beta_{i.}+\bar\varepsilon_{ij.}-\bar\varepsilon_{i..}$

$E[\bar y_{ij.}-\bar y_{i..}]=E[\beta_{ij}-\bar\beta_{i.}+\bar\varepsilon_{ij.}-\bar\varepsilon_{i..}]=0$

$Cov(\beta_{ij},\bar\beta_{i.})=\frac{1}{b}Cov(\beta_{ij},\sum_{j=1}^b\beta_{ij})=\frac1b[1\cdot\sigma_{\beta}^2+(b-1)\cdot0]$

$Cov(\bar\varepsilon_{ij.},\bar\varepsilon_{i..})=Cov(\frac{1}{n}\sum_{k=1}^n\varepsilon_{ijk},\frac{1}{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk})=\frac{1}{b}\frac{\sum_{k=1}^n}{n^2}Cov(\varepsilon_{ijk},\sum_{j=1}^b\varepsilon_{ijk})=\frac{1}{bn}\sigma_{\varepsilon}^2$

$Var[\bar y_{ij.}-\bar y_{i..}]=Var[\beta_{ij}-\bar\beta_{i.}+\bar\varepsilon_{ij.}-\bar\varepsilon_{i..}]=Var[\beta_{ij}-\bar\beta_{i.}]+Var[\bar\varepsilon_{ij.}-\bar\varepsilon_{i..}]$
$=Var[\beta_{ij}]+Var[\bar\beta_{i.}]-2Cov(\beta_{ij},\bar\beta_{i.})+Var[\bar\varepsilon_{ij.}]+Var[\bar\varepsilon_{i..}]-2Cov(\bar\varepsilon_{ij.},\bar\varepsilon_{i..})$
$=\sigma_{\beta}^2+\frac{1}{b}\sigma_{\beta}^2-\frac2b\sigma_{\beta}^2+\frac{1}{n}\sigma_{\varepsilon}^2+\frac{1}{bn}\sigma_{\varepsilon}^2-\frac{2}{bn}\sigma_{\varepsilon}^2=\frac{b-1}{b}(\sigma_{\varepsilon}^2+\frac{1}{n}\sigma_{\varepsilon}^2)$

$E[\sum_{i=1}^a\sum_{j=1}^b(\bar y_{ij.}-\bar y_{i..})^2]=\sum_{i=1}^a\sum_{j=1}^b(Var[\bar y_{ij.}-\bar y_{i..}]+E[\bar y_{ij.}-\bar y_{i..}]^2)$
$\sum_{i=1}^a\sum_{j=1}^b[\frac{b-1}{b}(\sigma_{\varepsilon}^2+\frac{1}{n}\sigma_{\varepsilon}^2)+0]=a(b-1)(\sigma_{\beta}^2+\frac1n\sigma_{\varepsilon}^2)$

\begin{tabular}{ l|l|l|l|l|l|l }
term &i(f) &j(r) &k(r) & df & EMS & F\\
$\alpha_{i}$f &0&b&n&a-1&$\frac{bn}{a-1}\sum_{i=1}^a\alpha_{i}+n\sigma^2_{\beta}+\sigma_{\varepsilon}^2$&$\frac{MS_{A}}{MS_{AB}}$\\
$\beta_{ij}$r &0&1&n&a(b-1)&$n\sigma^2_{\beta}+\sigma_{\varepsilon}^2$&$\frac{MS_{AB}}{MS_{E}}$\\
$\varepsilon_{ijk}$r&1&1&1&ab(n-1)&$\sigma_{\varepsilon}^2$\\
Total& & & &abn-1\\
\end{tabular}

$\hat\sigma^2=\frac{MS_{AB}-MS_{E}}n$; $E[\hat\sigma^2]=\frac1n(n\sigma^2_{\beta}+\sigma_{\varepsilon}^2-\sigma_{\varepsilon}^2)=\sigma^2_{\beta}$


##### Nested model

\begin{tabular}{ l|l|l|l|l|l|l|l }
term &i(f) &j(r) &k(f) &l(r) & df & EMS & F\\
A$\tau_{i}$f&0&b&c&n&a-1&$\frac{bcn\sum_{i=1}^{a}\tau_i^2}{a-1}+cn\sigma^2_{\beta}+\sigma^2$&$\frac{MS_{A}}{MS_{B(A)}}$\\
B(A)$\beta_{j(i)}$r&1&1&c&n&a(b-1)&$cn\sigma^2_{\beta}+\sigma^2$&$\frac{MS_{B(A)}}{MS_{E}}$\\
C$(\gamma)_{k}$f&a&b&0&n&c-1&$\frac{abn\sum_{k=1}^{c}\gamma_k^2}{c-1}+bn\sigma^2_{\gamma}+n\sigma^2_{\gamma\beta}+\sigma^2$&$\frac{MS_{C}}{MS_{CB(A)}}$\\
AC$(\tau\gamma)_{ik}$f&0&b&0&n&(a-1)(c-1)&$\frac{bn\sum_{i=1}^{a}\sum_{k=1}^{c}(\tau\gamma)_{ik}^2}{(a-1)(c-1)}+n\sigma^2_{\gamma\beta}+\sigma^2$&$\frac{MS_{AC}}{MS_{CB(A)}}$\\
CB(A)$(\gamma\beta)_{kj(i)}$r&1&1&0&n&a(b-1)(c-1)&$n\sigma^2_{\gamma\beta}+\sigma^2$&$\frac{MS_{CB(A)}}{MS_{E}}$\\
E$\varepsilon_{(ijk)l}$&1&1&1&1&abc(n-1)&$\sigma^2$\\
T& & & & &abcn-1
\end{tabular}

