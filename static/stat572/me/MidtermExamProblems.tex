\documentclass[12pt]{article}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[utf8]{inputenc}	% Para caracteres en espaÃ±ol
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{multirow,booktabs}
\usepackage[table]{xcolor}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{wrapfig}
\usepackage{setspace}
\usepackage{calc}
\usepackage{multicol}
\usepackage{cancel}
%\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}
\usepackage{float}
\newlength{\tabcont}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}
\usepackage{empheq}
\usepackage{framed}
\usepackage[most]{tcolorbox}
\usepackage{xcolor}
\colorlet{shadecolor}{orange!15}
\parindent 0in
\parskip 12pt
\geometry{margin=1in, headsep=0.25in}


\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\mbs}[1]{\boldsymbol{#1}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\N}{\mbb{N}_0}
\renewcommand{\d}{\text{d}}
\newcommand{\by}{\mbf{y}}
\newcommand{\mts}{\tilde{Y}}
\newcommand{\mtsv}{\tilde{\bv}}
\newcommand{\btw}{\tilde{\bw}}
\newcommand{\bhw}{\hat{\bw}}
\newcommand{\btx}{\tilde{\bx}}
\newcommand{\pt}{\tilde{p}}
\newcommand{\ba}{\mbf{a}}
\newcommand{\bb}{\mbf{b}}
\newcommand{\bc}{\mbf{c}}
\newcommand{\bd}{\mbf{d}}
\newcommand{\boe}{\mbf{e}}
\newcommand{\bk}{\mbf{k}}
\newcommand{\bq}{\mbf{q}}
\newcommand{\br}{\mbf{r}}
\newcommand{\bs}{\mbf{s}}
\newcommand{\bh}{\mbf{h}}
\newcommand{\bff}{\mbf{f}}
\newcommand{\bt}{\mbf{t}}
\newcommand{\bu}{\mbf{u}}
\newcommand{\bm}{\mbf{m}}
\newcommand{\bv}{\mbf{v}}
\newcommand{\bx}{\mbf{x}}
\newcommand{\bw}{\mbf{w}}
\newcommand{\tw}{\tilde{w}}
\newcommand{\bz}{\mbf{z}}
\newcommand{\tby}{\tilde{\mbf{y}}}
\newcommand{\tW}{\tilde{W}}
\newcommand{\bp}{\mbs{p}}
\newcommand{\bA}{\mbf{A}}
\newcommand{\tbA}{\tilde{\bA}}
\newcommand{\bB}{\mbf{B}}
\newcommand{\bC}{\mbf{C}}
\newcommand{\tc}{\tilde{c}}
\newcommand{\tC}{\tilde{C}}
\newcommand{\tbC}{\tilde{\bC}}
\newcommand{\bF}{\mbf{F}}
%\newcommand{\bBs}{\mbf{B}^\star}
\newcommand{\bD}{\mbf{D}}
\newcommand{\bM}{\mbf{M}}
\newcommand{\bK}{\mbf{K}}
\newcommand{\bQ}{\mbf{Q}}
\newcommand{\bV}{\mbf{V}}
\newcommand{\bX}{\mbf{X}}
\newcommand{\bY}{\mbf{Y}}
\newcommand{\bZ}{\mbf{Z}}
\newcommand{\bW}{\mbf{W}}
\newcommand{\hN}{\hat{N}}
\newcommand{\tbc}{\tilde{\mbf{c}}}
\newcommand{\tba}{\tilde{\mbf{a}}}
\newcommand{\tbX}{\tilde{\mbf{X}}}
\newcommand{\tbW}{\tilde{\mbf{W}}}
\newcommand{\bSigma}{\mbs{\Sigma}}
\newcommand{\bGamma}{\mbs{\Gamma}}
\newcommand{\bUps}{\mbs{\Upsilon}}
\newcommand{\bPsi}{\mbs{\Psi}}
\newcommand{\vs}{v^\star}
\newcommand{\Vs}{V^\star}
\newcommand{\bvs}{\bv_i^\star}
\newcommand{\bR}{\mbf{R}}
\newcommand{\bP}{\mbf{P}}
\newcommand{\bBs}{\bB^\star}
\newcommand{\bXs}{\bX^\star}
\newcommand{\bxs}{\bx^\star}
\newcommand{\bWs}{\bW^\star}
\newcommand{\bws}{\bw_i^\star}
\newcommand{\bwsp}{\left.\bw_i^\star\right.^\prime}
\newcommand{\bBsp}{\left.\bB^\star\right.^\prime}
\newcommand{\bVs}{\bV^\star}
\newcommand{\bpsi}{\mbs{\psi}}
\newcommand{\bphi}{\mbs{\phi}}
\newcommand{\bmu}{\mbs{\mu}}
\newcommand{\bbeta}{\mbs{\beta}}
\newcommand{\bxi}{\mbs{\xi}}
\newcommand{\bchi}{\mbs{\chi}}
\newcommand{\blambda}{\mbs{\lambda}}
\newcommand{\bLambda}{\mbs{\Lambda}}
\newcommand{\LamT}{\tilde{\Lambda}}
\newcommand{\GamT}{\tilde{\Gamma}}
\newcommand{\WT}{\tilde{W}}
\newcommand{\balpha}{{\mbs{\alpha}}}
\newcommand{\bepsilon}{{\mbs{\varepsilon}}}
\newcommand{\bgamma}{{\mbs{\gamma}}}
\newcommand{\btheta}{{\mbs{\theta}}}
\newcommand{\bseta}{{\mbs{\eta}}}
\newcommand{\bpi}{{\mbs{\pi}}}
\newcommand{\bI}{\mbf{I}}
\newcommand{\bH}{\mbf{H}}
\newcommand{\tbH}{\tilde{\mbf{H}}}
\newcommand{\1}{\mbs{1}}
\newcommand{\0}{\mbs{0}}
\newcommand{\detstar}[1]{\text{det}^+\left(#1\right)}
\renewcommand{\det}[1]{\text{det}\left(#1\right)}
\newcommand{\rank}[1]{\text{rank}\left(#1\right)}
\renewcommand{\exp}[1]{\text{exp}\left[#1\right]}
\newcommand{\M}{{M}}
\newcommand{\K}{{K}}
\newcommand{\peq}{{p}}
\newcommand{\MB}{{M_B}}
\newcommand{\MF}{{M_F}}
\newcommand{\MT}{{M_T}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\graph}{\Gamma}
\newcommand{\kset}{\Upsilon}
\newcommand{\order}{order}
\newcommand{\parents}{\mcal{P}}
\newcommand{\children}{\mcal{C}}
\newcommand{\extreme}{\mcal{E}}
\newcommand{\combined}{\mcal{A}}
\newcommand{\ind}{\perp\!\!\!\perp}
\newcommand{\lrp}[1]{\left(#1\right)}
\newcommand{\lrb}[1]{\left\{#1\right\}}
\newcommand{\lrno}[1]{\left.#1\right.}
\newcommand{\lrsqb}[1]{\left[#1\right]}
\newcommand{\G}[1]{\Gamma_{#1}}
\renewcommand{\d}{\text{d}}
\newcommand{\Ps}[1]{\Pr{\left(#1\right)}}
\newcommand{\BF}[2]{{BF}_{#1,#2}(Y)}
\newcommand{\BFd}[3]{{BF}_{#1,#2}(Y,#3)}
\newcommand{\xmark}{\ding{55}}
\newcommand{\ben}{\begin{equation*}}
\newcommand{\een}{\end{equation*}}
\newcommand{\bean}{\begin{eqnarray*}}
\newcommand{\eean}{\end{eqnarray*}}
\newcommand{\bsm}{\begin{smallmatrix}}
\newcommand{\esm}{\end{smallmatrix}}
\newcommand{\bmat}{\begin{matrix}}
\newcommand{\emat}{\end{matrix}}
\newcommand{\tI}{\text{I}}
\newcommand{\tN}{\text{N}}
\newcommand{\trN}{\text{trunc.N}}
\newcommand{\nl}[1]{\text{log}{\lrp{#1}}}
\newcommand{\e}[1]{\text{exp}{\lrb{#1}}}
\newcommand{\indf}[1]{\tI_{\left\{#1\right\}}}
\newcommand{\parent}{\mcal{P}}
\newcommand{\gp}{\text{GP}{\lrp{\0,\mcal{C}(\cdot\given\bphi)}}}
\newcommand{\gpd}[3]{\text{GP}_{#1}{\lrp{\0,\mcal{C}_{#2}(\cdot\given\phi_{#3})}}}
\newcommand{\mnngpd}[3]{\text{NNGP}_{#1}{\lrp{\0,\tilde{\mbs{\mcal{C}}}_{#2}(\cdot,\cdot;\bphi_{#3})}}}
\newcommand{\nngpd}[3]{\text{NNGP}_{#1}{\lrp{\0,\tilde{\mcal{C}}_{#2}(\cdot,\cdot;\phi_{#3})}}}
\newcommand{\nngpw}[4]{\text{NNGP}_{#1}^{#2}{\lrp{0,\tilde{\mcal{C}}_{#2}(\cdot\given \phi_{#3}^{#4})}}}
\newcommand{\gpw}[4]{\text{GP}_{#1}^{#2}{\lrp{0,\mcal{C}_{#2}(\cdot\given \phi_{#3}^{#4})}}}
\newcommand{\gpq}{\text{GP}_q{\lrp{\0,\mbs{\mcal{C}}(\cdot\given\bphi)}}}
\newcommand{\gpk}{\text{GP}{\lrp{0,\mcal{C}(\cdot\given\tilde{\phi}_k)}}}
\newcommand{\nngp}{\text{NNGP}{\lrp{\0,\tilde{\mcal{C}}(\cdot\given\phi)}}}
\newcommand{\refset}{\mcal{T}}
\newcommand{\uset}{\mcal{U}}
\newcommand{\oset}{\mcal{T}}
\newcommand{\Xall}{\mbb{X}}
\newcommand{\given}{\,|\,}
\newcommand{\dtr}[1]{\textcolor{blue}{(#1)}}
\newcommand{\bemph}[1]{\bf \emph{#1}}
\newcommand{\var}[1]{\text{var}{(#1)}}

%-------------------------------
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{reg}{Rule}
\newtheorem{exer}{Exercise}
\newtheorem{exa}{Example}
\newtheorem{note}{Note}
\newcommand{\bex}{\begin{exer}}
\newcommand{\eex}{\end{exer}}
\newcommand{\bexa}{\begin{exa}}
\newcommand{\eexa}{\end{exa}}
\newcommand{\bit}{\begin{itemize}}
\newcommand{\eit}{\end{itemize}}
\newcommand{\benum}{\begin{enumerate}}
\newcommand{\eenum}{\end{enumerate}}
\newcommand{\bdes}{\begin{description}}
\newcommand{\edes}{\end{description}}

\newcommand{\bsh}{\begin{shaded}}
\newcommand{\esh}{\end{shaded}}
%-------------------------------

%-------------------------------
%hiding proof solutions
%-------------------------------
\newif\ifhideproofs
\hideproofstrue %uncomment to hide proofs

\ifhideproofs
\usepackage{environ}
\NewEnviron{hide}{}
\let\proof\hide
\let\endproof\endhide
\fi
%-------------------------------
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


\setcounter{section}{0}
\title{%
STAT 572: Bayesian Statistics\\
Midterm Exam Practice Problems}

\author{}

\date{}							% Activate to display a given date or no date

\maketitle

\thispagestyle{empty}

\section*{Instructions}

Work on these problems individually or a as a group.  Make sure you understand exactly what the questions are asking for. I will provide solutions on Monday November 11th at 9 am. It is in your best interest to have diligently attempted all of the problems in the set by then, and be absolutely certain you have understood the solutions to all questions before the exam.

\begin{center}
{\Large In all exercises you must show your work to receive full credit.}
\end{center}

\section*{List of Functions and Useful Identities}

\bean
B(a,b)&=&\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\\
\Gamma(x+1)&=&x\Gamma(x)\text{ for }x>0\\
\Gamma(k+1)&=&k!\text{ for }k\in\lrb{1,2,3,\ldots}\\
x^a&=& e^{a\ln{x}}\text{ for }a\in\mathbb{R},\,x>0\\
\ln{\lrp{a\cdot b}}&=& \ln{a}+\ln{b}\\
\ln{\lrp{a/ b}}&=& \ln{\lrp{a}}-\ln{\lrp{b}}
\eean

\section*{Exponential Family Formulas}

\bean
\text{Exponential family form}&&\\
p(y_{1:n} \given \theta) &=& \e{t(y)\varphi(\theta) -n\kappa(\theta)}h(y_{1:n})\\
&&\\
\text{General form conjugate priors expt family}&&\\
p_{n_0,t_0}(\theta) &\propto& \e{t_0 n_0 \varphi(\theta) - n_0\kappa(\theta)}
\eean

\section*{List of  Distributions}

{\footnotesize
\bean
\text{Bernoulli}(y\given \theta)&=& \theta^y (1-\theta)^{1-y} \1_{\lrb{y\in\lrb{0,1}}},\;\theta\in(0,1)\\
\text{Binomial}(y\given n, \theta)&=& {n\choose y} \theta^y (1-\theta)^{n-y} \1_{\lrb{y\in\lrb{0,1,2,\ldots,n}}},\;\theta\in(0,1)\\
\text{Poisson}(y\given \theta)&=& \frac{\theta^y e^{-\theta}}{y!} \1_{\lrb{y\in\lrb{0,1,2,\ldots}}},\;\theta>0\\
\text{Geometric}(y\given n, \theta)&=&  (1-\theta)^{y-1}\theta  \1_{\lrb{y\in\lrb{1,2,\ldots}}},\;\theta\in(0,1)\\
\text{Neg.Binom}(y\given r,\theta)&=&{y+r-1\choose y}(1-\theta)^r \theta^y \1_{\lrb{y\in\lrb{0,1,2,\ldots}}},\; r>0,\;\theta\in(0,1)\\
\text{Uniform}(y\given a,b)&=& \frac{1}{b-a}\1_{\lrb{y\in(a,b)}},\;-\infty<a<b<\infty\\
\text{Beta}(y\given a,b)&=& \frac{1}{B(a,b)}y^{a-1}(1-y)^{b-1} \1_{\lrb{y\in(0,1)}},\;a,b>0\\
\text{Exp}(y\given \theta)&=&\theta e^{-y \theta} \1_{\lrb{y>0}},\;\theta>0\\
\text{Gamma}(y\given a,b)&=&\frac{b^a}{\Gamma(a)}y^{a-1}e^{-y b} \1_{\lrb{y>0}},\;a,b>0\\
\text{InvGamma}(y\given a,b)&=&\frac{b^a}{\Gamma(a)} y^{-a-1} e^{-\frac{b}{y}} \1_{\lrb{y>0}},\;a,b>0\\
\tN(y\given \mu,\sigma^2)&=& \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2\sigma^2}(y-\mu)^2},\;\mu,\sigma^2>0\\
&\text{or}&\sqrt{\frac{\lambda}{2\pi}}e^{-\frac{\lambda}{2}(y-\mu)^2}\quad\text{where }\lambda=1/\sigma^2,\;\mu\in\mathbb{R},\lambda>0\\
\text{Pareto}(y\given a,b)&=&\frac{a\,b^a}{y^{a+1}}\1_{\lrb{y>b}},\;a,b>0
\eean
}




\pagebreak

\section*{Problems}

\benum
\item (Marginal Likelihood) Assume that the random sample $X_1,\ldots,X_n \sim \text{Geometric}(\theta)$ given $\theta$. Consider a Beta$(a, b)$ prior on $\theta$. Obtain the marginal likelihood $p(x_{1:n})$.

(Your answer must be an explicit expression in terms of $a, b, x_1,\ldots,x_n, n$, and any of the functions provided on page 2.)


\item (Exponential family) Show that the collection of $\tN(\mu,\sigma^2)$ distributions, with $\mu\in\mathbb{R}$ and  $\sigma^2>0$, is a two-parameter exponential family, and identify the sufficient statistics function $t(y_{1:n}) = (t_1(y_{1:n}), t_2(y_{1:n}))^T$ for your parametrization.

\item (Conjugate priors) Assume that $Y_1,\ldots,Y_n\overset{iid}{\sim}\text{Uniform}(0,\theta)$ given $\theta$, that is
$$p(y_i\given \theta)= \frac{1}{\theta}\1_{\lrb{0< y_i < \theta}}. $$

We want to find a conjugate prior for $\btheta$. Show that the family of Pareto$(a,b)$ distributions, with $a> 0$ and $b > 0$, is a conjugate prior family.


\item (Posterior predictive) A dataset with $n$ observations $Y_1,\ldots,Y_n$ is modeled as iid Exp$(\theta)$ with prior $p(\theta) = \text{Gamma}(\theta \given a, b)$. We know that the posterior is $$p(\theta\given y_{1:n}) = \text{Gamma}(\theta\given \alpha, \beta),$$ where $\alpha = a + n$ and $\beta = b + \sum_{i=1}^n y_i$.

What is the posterior predictive density $p(\tilde{y}\given y_{1:n})$? Give your answer as a closed-form expression (not an integral).

\item (Normal) In 1882, Simon Newcomb made 66 measurements of the amount of time it took for light to travel from his laboratory on the Potomac River, to a mirror placed at the base of the Washington Monument, and back. Converted to speed, in units of ×108 meters/second, his data was as follows:
{\small
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{speed} \hlkwb{<-} \hlkwd{read.csv}\hlstd{(}\hlstr{"dataLightSpeed.csv"}\hlstd{,}\hlkwc{header}\hlstd{=F)}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning in file(file, "{}rt"{}): cannot open file 'dataLightSpeed.csv': No such file or directory}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in file(file, "{}rt"{}): cannot open the connection}}\begin{alltt}
\hlkwd{c}\hlstd{(speed}\hlopt{$}\hlstd{V1)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in eval(expr, envir, enclos): object 'speed' not found}}\begin{alltt}
\hlcom{#sample size}
\hlstd{(n} \hlkwb{<-} \hlkwd{length}\hlstd{(speed}\hlopt{$}\hlstd{V1))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in eval(expr, envir, enclos): object 'speed' not found}}\begin{alltt}
\hlcom{#sample mean}
\hlstd{(y.bar}\hlkwb{=}\hlkwd{mean}\hlstd{(speed}\hlopt{$}\hlstd{V1))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in mean(speed\$V1): object 'speed' not found}}\begin{alltt}
\hlcom{#sample variance}
\hlstd{(S.sq} \hlkwb{=} \hlkwd{sum}\hlstd{((speed}\hlopt{$}\hlstd{V1}\hlopt{-}\hlstd{y.bar)}\hlopt{^}\hlnum{2}\hlstd{)}\hlopt{/}\hlstd{(n}\hlopt{-}\hlnum{1}\hlstd{))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in eval(expr, envir, enclos): object 'speed' not found}}\end{kframe}
\end{knitrout}
}


You are interested in determining the speed of light. Assume that it makes sense to have your independent speed measurements $Y_1,\ldots,Y_{66}$ follow a $\tN(\mu,\sigma^2)$ distribution. 

\benum
\item Specify a Normal-Inverse Gamma prior for $\mu, \sigma^2$ (i.e., choose suitable parameter values for the prior), and justify your choices.

\item Derive the posterior $p(\bmu, \mbs{\sigma}^2\given y_{1:n})$, showing all of your steps.
\eenum

\item  (Normal and marginal) Suppose $Y_1,\ldots,Y_n \sim \tN(\theta,\sigma^2)$, that $\sigma^2$ is known, and that $\btheta$ is given a $\tN(\mu_0,\sigma_0^2)$ prior.
\benum
\item When $n = 1$, what is the marginal likelihood, $p(y_1)$?
\item When $n > 1$, is it true that the marginal likelihood factors as $p(y_{1:n}) = p(y_1)\cdots p(y_n)$?
\eenum


\item (Monte Carlo) If we are interested in the tail probability $\Pr(X> 20)$ when $X \sim N(0, 1)$, simulating from a $N(0, 1)$ distribution does not work. Express the probability as an integral and use an obvious change of variable to rewrite this integral as an expectation under a $U(0, 1/20)$ distribution. Deduce a Monte Carlo approximation to $\Pr(X > 20)$ along with an error assessment. Compare the performance of this estimator to that of the direct Monte Carlo estimator.

\item (Monte Carlo) For the computation of the expectation $E[h(X)]$ when $X\sim N(0,1)$ and $$h(x)=exp\{-\frac{1}{2}(x - 3)^2\} + exp\{-\frac{1}{2}(x - 6)^2\}$$
\benum
\item Show that $E[h(X)]$ can be computed in closed form and derive its value. 
\item Construct a regular Monte Carlo approximation based on a normal $N(0, 1)$ sample of size $S=10^3$ and produce an error evaluation.
\eenum


 \item (Gibbs Sampling) Consider the following Exponential model for an observation $x$: $$p(x \given a, b) = a\, b\, e^{-a\, b\, x}\1_{\lrb{x > 0}},$$
and suppose the prior is
 $$p(a, b) \propto e^{-(a + b)}\1_{\lrb{a, b > 0}}.$$
You want to sample from the posterior $p(a, b \given x)$. Derive the conditional distributions needed for implementing a Gibbs sampler, and write out the steps to implement the Gibbs Sampling algorithm.

\eenum



\end{document}
